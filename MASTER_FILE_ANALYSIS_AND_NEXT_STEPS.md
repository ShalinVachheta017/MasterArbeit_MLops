# ğŸ“‹ MASTER FILE ANALYSIS & NEXT STEPS
## Thesis MLOps Project - January 2026

**Generated:** January 6, 2026  
**Purpose:** Categorize all files (KEEP/DELETE/LATER) and define clear next steps

---

## ğŸ“ FILE CATEGORIZATION

### Legend
- ğŸŸ¢ **KEEP** - Essential, actively used
- ğŸ”´ **DELETE** - Outdated, redundant, or already archived
- ğŸŸ¡ **LATER** - May be useful in future phases

---

## ROOT LEVEL FILES

| File | Decision | Reason |
|------|----------|--------|
| `README.md` | ğŸŸ¢ KEEP | Main project documentation |
| `PROJECT_GUIDE.md` | ğŸŸ¢ KEEP | Complete folder/file reference |
| `Thesis_Plan.md` | ğŸŸ¢ KEEP | 6-month timeline (essential) |
| `COMPREHENSIVE_THESIS_STATUS.md` | ğŸŸ¡ LATER | Outdated (Dec 2025), merge into new status |
| `WHAT_TO_DO_NEXT.md` | ğŸ”´ DELETE | Outdated (Dec 2025), will be replaced |
| `TODO_THIS_WEEK.md` | ğŸ”´ DELETE | Outdated (Dec 2025), no longer relevant |
| `LEARNINGS_FROM_REFERENCE_PROJECT.md` | ğŸŸ¢ KEEP | Valuable architecture patterns |
| `Technology Stack Analysis.md` | ğŸŸ¢ KEEP | Tech decisions reference |
| `imp.md` | ğŸŸ¢ KEEP | Production robustness guide |
| `docker-compose.yml` | ğŸŸ¢ KEEP | Docker orchestration |
| `dvc_experiments.html` | ğŸ”´ DELETE | Auto-generated, can recreate |

---

## docs/ FOLDER

| File | Decision | Reason |
|------|----------|--------|
| `docs/CURRENT_STATUS.md` | ğŸ”´ DELETE | Outdated (Dec 6, 2025) |
| `docs/PIPELINE_RERUN_GUIDE.md` | ğŸŸ¢ KEEP | Essential for running pipeline |
| `docs/FRESH_START_CLEANUP_GUIDE.md` | ğŸŸ¢ KEEP | Useful for cleanup |
| `docs/FILE_ORGANIZATION_SUMMARY.md` | ğŸ”´ DELETE | Outdated cleanup reference |
| `docs/MARKDOWN_CLEANUP_GUIDE.md` | ğŸ”´ DELETE | Already done cleanup |
| `docs/CONCEPTS_EXPLAINED.md` | ğŸŸ¢ KEEP | Educational reference |
| `docs/RESEARCH_PAPER_INSIGHTS.md` | ğŸŸ¢ KEEP | Valuable paper analysis |
| `docs/RESEARCH_PAPERS_ANALYSIS.md` | ğŸŸ¢ KEEP | ICTH_16 & EHB_2025_71 analysis |
| `docs/SRC_FOLDER_ANALYSIS.md` | ğŸ”´ DELETE | One-time analysis |
| `docs/QA_LAB_TO_LIFE_GAP.md` | ğŸŸ¢ KEEP | Important Q&A for thesis |
| `docs/archived/` | ğŸ”´ DELETE | Already marked for deletion |
| `docs/archived_status/` | ğŸ”´ DELETE | Outdated status files |

---

## ai helps/ FOLDER

| File | Decision | Reason |
|------|----------|--------|
| `ai helps/FINAL_Thesis_Status_and_Plan_Jan_to_Jun_2026.md` | ğŸŸ¢ KEEP | Comprehensive plan |
| `ai helps/offline-mlops-guide.md` | ğŸŸ¡ LATER | Edge deployment reference |
| `ai helps/extranotes.md` | ğŸ”´ DELETE | Temporary notes |

---

## research_papers/ FOLDER

| File | Decision | Reason |
|------|----------|--------|
| `76_papers_suggestions.md` | ğŸŸ¢ KEEP | Paper recommendations |
| `76_papers_summarizzation.md` | ğŸŸ¢ KEEP | Paper summaries |
| `COMPREHENSIVE_RESEARCH_PAPERS_SUMMARY.md` | ğŸŸ¢ KEEP | Best paper analysis |
| `all_users_data_labeled.csv` | ğŸŸ¢ KEEP | Training data |
| `anxiety_dataset.csv` | ğŸŸ¢ KEEP | Additional dataset |
| `76 papers/` | ğŸŸ¢ KEEP | PDF collection |

---

## data/ FOLDER

| Subfolder | Decision | Reason |
|-----------|----------|--------|
| `data/raw/` | ğŸŸ¢ KEEP | Source data |
| `data/preprocessed/` | ğŸŸ¢ KEEP | Pipeline output |
| `data/prepared/` | ğŸŸ¢ KEEP | Model-ready data |
| `data/prepared/DATA_COMPARISON_REPORT.md` | ğŸ”´ DELETE | One-time analysis |
| `data/prepared/PRODUCTION_DATA_README.md` | ğŸŸ¢ KEEP | Data documentation |

---

## notebooks/ FOLDER

| File | Decision | Reason |
|------|----------|--------|
| `data_preprocessing_step1.ipynb` | ğŸŸ¢ KEEP | Preprocessing reference |
| `production_preprocessing.ipynb` | ğŸŸ¢ KEEP | Production preprocessing |
| `from_guide_processing.ipynb` | ğŸŸ¡ LATER | Experimental |
| `data_comparison.ipynb` | ğŸ”´ DELETE | One-time comparison |
| `scalable.ipynb` | ğŸ”´ DELETE | Experimental |
| `exploration/` | ğŸŸ¡ LATER | Exploration notebooks |

---

## src/ FOLDER

| File | Decision | Reason |
|------|----------|--------|
| `config.py` | ğŸŸ¢ KEEP | Core configuration |
| `preprocess_data.py` | ğŸŸ¢ KEEP | Core preprocessing |
| `run_inference.py` | ğŸŸ¢ KEEP | Core inference |
| `sensor_data_pipeline.py` | ğŸŸ¢ KEEP | Core data pipeline |
| `mlflow_tracking.py` | ğŸŸ¢ KEEP | Experiment tracking |
| `data_validator.py` | ğŸŸ¢ KEEP | Data validation |
| `evaluate_predictions.py` | ğŸŸ¢ KEEP | Evaluation logic |
| `compare_data.py` | ğŸ”´ DELETE | One-time comparison |
| `Archived(...)/` | ğŸŸ¢ KEEP | Archive for old code |

---

# ğŸ¯ WHAT TO DO NEXT

## The Core Problem

**Your pipeline is INFERENCE-ONLY, not TRAINING.**

Current flow:
```
Raw Garmin Data â†’ Preprocess â†’ Pretrained Model â†’ Predictions
```

What's missing for production:
```
New Labeled Data â†’ Retrain with CV â†’ Updated Model â†’ Deploy â†’ Monitor â†’ Repeat
```

---

## Priority 1: RETRAINING PIPELINE (Week 1-2)

### Why Retraining?
Per ICTH_16 paper: *"Weekly retraining with 10-20% new labeled data maintains 85%+ accuracy"*

### When to Trigger Retraining?
Options from research papers:

| Trigger | Description | Paper Source |
|---------|-------------|--------------|
| **Scheduled** | Every week (cron job) | ICTH_16 |
| **Data Volume** | After N new labeled samples | MLOps Survey |
| **Drift Detected** | When data distribution shifts | Domain Adaptation papers |
| **Performance Drop** | When accuracy < threshold | MLOps Best Practices |

### Recommended: Scheduled + Drift-based

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RETRAINING TRIGGER LOGIC                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  IF (weekly_schedule_reached) OR (drift_score > 0.1):       â”‚
â”‚      IF (new_labeled_samples > 100):                        â”‚
â”‚          run_retraining_with_cv()                           â”‚
â”‚          IF (new_accuracy > current_accuracy - 0.02):       â”‚
â”‚              deploy_new_model()                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Priority 2: CI/CD PIPELINE (Week 2-3)

### Minimal CI/CD for Thesis

```yaml
# .github/workflows/mlops.yml
name: MLOps Pipeline

on:
  push:
    branches: [main]
  schedule:
    - cron: '0 0 * * 0'  # Weekly (Sunday midnight)

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run tests
        run: pytest tests/ -v

  retrain:
    needs: test
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    steps:
      - name: Check for new data
        run: python scripts/check_new_data.py
      - name: Retrain with CV
        run: python src/retrain_with_cv.py
      - name: Deploy if better
        run: python scripts/deploy_if_better.py
```

---

## Priority 3: DRIFT DETECTION (Week 3-4)

### Simple Drift Detection

```python
# src/drift_detector.py
from scipy.stats import ks_2samp
import numpy as np

def detect_drift(reference_data, new_data, threshold=0.1):
    """
    Detect distribution shift using Kolmogorov-Smirnov test.
    Per Domain Adaptation papers: KS-test is simple but effective.
    """
    drift_scores = {}
    for col in ['Ax_w', 'Ay_w', 'Az_w', 'Gx_w', 'Gy_w', 'Gz_w']:
        statistic, p_value = ks_2samp(reference_data[col], new_data[col])
        drift_scores[col] = statistic
    
    avg_drift = np.mean(list(drift_scores.values()))
    return {
        'drift_detected': avg_drift > threshold,
        'drift_score': avg_drift,
        'per_feature': drift_scores
    }
```

---

## Priority 4: MONITORING DASHBOARD (Week 4-5)

### Simple Prometheus + Grafana

Already in docker-compose pattern, just needs metrics endpoints:

```python
# Add to FastAPI
from prometheus_client import Counter, Histogram, generate_latest

PREDICTIONS = Counter('predictions_total', 'Total predictions', ['activity'])
LATENCY = Histogram('prediction_latency_seconds', 'Prediction latency')

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

---

# ğŸ”¬ RESEARCH QUESTIONS TO EXPLORE

These questions can be researched online or asked in NotebookLM:

## Domain Adaptation Questions

1. **"How to implement unsupervised domain adaptation for wearable HAR when target domain has no labels?"**
   - Key papers: CORAL, MMD, DANN
   - Search: "unsupervised domain adaptation IMU sensors"

2. **"What is the minimum number of labeled target samples needed for effective fine-tuning?"**
   - ICTH_16 suggests: 10-20% of source domain size
   - Search: "few-shot domain adaptation HAR"

3. **"Can we use contrastive learning to align source and target sensor distributions?"**
   - Key papers: SimCLR, MoCo for time-series
   - Search: "contrastive learning sensor data domain adaptation"

## Retraining Questions

4. **"How often should HAR models be retrained in production?"**
   - ICTH_16: Weekly with new data
   - Search: "model retraining frequency machine learning production"

5. **"What triggers model retraining: scheduled, drift-based, or performance-based?"**
   - MLOps papers suggest: combination
   - Search: "model retraining triggers MLOps"

6. **"How to implement online learning for HAR without forgetting old activities?"**
   - Key concept: Catastrophic forgetting
   - Search: "continual learning HAR wearables"

## MLOps Questions

7. **"What's the minimal CI/CD pipeline for a thesis-level MLOps project?"**
   - GitHub Actions + pytest + Docker
   - Search: "minimal MLOps pipeline academic project"

8. **"How to version models and data together in a reproducible way?"**
   - DVC + MLflow combination
   - Search: "DVC MLflow integration reproducibility"

---

# ğŸ“Š SUMMARY TABLE

| Priority | Task | Effort | Research Support |
|----------|------|--------|------------------|
| 1 | Retraining Pipeline with CV | 1-2 weeks | ICTH_16: weekly retraining |
| 2 | CI/CD (GitHub Actions) | 1 week | MLOps Survey |
| 3 | Drift Detection | 3-4 days | Domain Adaptation papers |
| 4 | Monitoring (Prometheus) | 3-4 days | MLOps Best Practices |
| 5 | Thesis Writing | 4-6 weeks | - |

---

# ğŸ—‘ï¸ FILES TO DELETE NOW

Run this command to clean up:

```powershell
# Root level
Remove-Item -Path "COMPREHENSIVE_THESIS_STATUS.md" -Force
Remove-Item -Path "WHAT_TO_DO_NEXT.md" -Force
Remove-Item -Path "TODO_THIS_WEEK.md" -Force
Remove-Item -Path "dvc_experiments.html" -Force

# docs/
Remove-Item -Path "docs/CURRENT_STATUS.md" -Force
Remove-Item -Path "docs/FILE_ORGANIZATION_SUMMARY.md" -Force
Remove-Item -Path "docs/MARKDOWN_CLEANUP_GUIDE.md" -Force
Remove-Item -Path "docs/SRC_FOLDER_ANALYSIS.md" -Force
Remove-Item -Path "docs/archived" -Recurse -Force
Remove-Item -Path "docs/archived_status" -Recurse -Force

# ai helps/
Remove-Item -Path "ai helps/extranotes.md" -Force

# data/prepared/
Remove-Item -Path "data/prepared/DATA_COMPARISON_REPORT.md" -Force

# notebooks/
Remove-Item -Path "notebooks/data_comparison.ipynb" -Force
Remove-Item -Path "notebooks/scalable.ipynb" -Force

# src/
Remove-Item -Path "src/compare_data.py" -Force
```

---

# âœ… NEXT IMMEDIATE ACTION

1. **Run the cleanup command above**
2. **Read `ai helps/FINAL_Thesis_Status_and_Plan_Jan_to_Jun_2026.md`** - This is your roadmap
3. **Create `src/retrain_with_cv.py`** - Retraining script with 5-fold CV
4. **Ask NotebookLM**: "How to trigger model retraining based on drift detection in HAR systems?"

---

*This file replaces: WHAT_TO_DO_NEXT.md, TODO_THIS_WEEK.md, COMPREHENSIVE_THESIS_STATUS.md*
