# âš ï¸ CRITICAL: Data Leakage Concern

**Date:** November 5, 2025  
**Issue:** We don't know which users the pretrained model was trained on!

---

## ğŸ” THE PROBLEM

### What We Know âœ…

```
Our Data Splits (Created by us):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Train:  Users 1, 2, 3, 4  (2,538 windows)
Val:    User 5            (641 windows)
Test:   User 6            (673 windows)

Evidence: Verified from metadata files
â”œâ”€ data/prepared/train_metadata.json â†’ users: 1,2,3,4
â”œâ”€ data/prepared/val_metadata.json   â†’ user: 5
â””â”€ data/prepared/test_metadata.json  â†’ user: 6
```

### What We DON'T Know âŒ

```
Pretrained Model Training:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Which users were used?
â”œâ”€ Maybe Users 1,2,3,4  (same as our train split) âœ…
â”œâ”€ Maybe ALL users 1-6  (includes our test user!) âš ï¸
â”œâ”€ Maybe different split (1,2,5 train; 3,4,6 test) â“
â””â”€ Maybe completely different dataset â“

Evidence: model_info.json has NO training info!
```

---

## ğŸš¨ WORST CASE SCENARIO

### If Pretrained Model Used ALL Users (Including User 6):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PRETRAINED MODEL TRAINING                       â”‚
â”‚         (By Mentor - Unknown)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Training Data: Users 1, 2, 3, 4, 5, 6  (ALL)         â”‚
â”‚                 â†‘                     â†‘                â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                   Includes User 6!                      â”‚
â”‚                                                         â”‚
â”‚               â†“ Train â†“                                â”‚
â”‚                                                         â”‚
â”‚         Pretrained Model                               â”‚
â”‚         (Already saw User 6!)                          â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         YOUR EVALUATION                                 â”‚
â”‚         (What you're trying to do)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Test Data: User 6 ONLY                                â”‚
â”‚             â†‘                                          â”‚
â”‚             â””â”€â”€ Already seen during training! âš ï¸        â”‚
â”‚                                                         â”‚
â”‚  Result: High accuracy (95%) BUT MEANINGLESS!          â”‚
â”‚                                                         â”‚
â”‚  Why? Model already memorized User 6's patterns!       â”‚
â”‚  This is DATA LEAKAGE! âŒ                              â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… BEST CASE SCENARIO

### If Pretrained Model Used ONLY Users 1-4:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PRETRAINED MODEL TRAINING                       â”‚
â”‚         (By Mentor)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Training Data: Users 1, 2, 3, 4  (ONLY)              â”‚
â”‚                                                         â”‚
â”‚               â†“ Train â†“                                â”‚
â”‚                                                         â”‚
â”‚         Pretrained Model                               â”‚
â”‚         (Never saw Users 5 or 6)                       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         YOUR EVALUATION                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Test Data: User 6 ONLY                                â”‚
â”‚             â†‘                                          â”‚
â”‚             â””â”€â”€ NEVER seen during training! âœ…          â”‚
â”‚                                                         â”‚
â”‚  Result: Accuracy (85-90%) AND MEANINGFUL!             â”‚
â”‚                                                         â”‚
â”‚  Why? Model generalizes to completely new user!        â”‚
â”‚  This is FAIR EVALUATION! âœ…                           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ HOW TO FIND OUT

### Option 1: Ask Your Mentor â­ BEST

```
Questions to Ask:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. Which users were used for training the pretrained model?
2. Which users were used for validation?
3. Which users were held out for testing?
4. What was the training/val/test split strategy?
5. Can you share the training logs or config?
```

### Option 2: Test on Production Data (Unlabeled)

```
Instead of testing on User 6:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Test on your OWN recorded data (unlabeled):
â”œâ”€ data/processed/sensor_fused_50Hz.csv
â”œâ”€ 181,699 samples
â”œâ”€ Completely different from all 6 users!
â””â”€ Guaranteed NO data leakage! âœ…

Problem: NO LABELS = Can't measure accuracy âŒ
Solution: Use monitoring + drift detection
```

### Option 3: Cross-User Evaluation

```
Evaluate on EACH user separately:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Test on User 1 â†’ Accuracy: 98% âš ï¸ (suspicious if high!)
Test on User 2 â†’ Accuracy: 97% âš ï¸
Test on User 3 â†’ Accuracy: 96% âš ï¸
Test on User 4 â†’ Accuracy: 95% âš ï¸
Test on User 5 â†’ Accuracy: 88% (reasonable)
Test on User 6 â†’ Accuracy: 87% (reasonable)

Pattern Analysis:
â”œâ”€ If Users 1-4 have MUCH higher accuracy â†’ Likely trained on them
â”œâ”€ If all users have similar accuracy â†’ Might be different split
â””â”€ If User 6 has lowest accuracy â†’ Good sign (hardest, unseen)
```

---

## ğŸ¯ RECOMMENDED APPROACH

### What You Should Do NOW:

```
STEP 1: Contact Mentor (HIGH PRIORITY)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Email your mentor:
"Hi Professor,

I'm evaluating the pretrained model you provided. To ensure 
proper validation without data leakage, could you please clarify:

1. Which users (1-6) were used for training?
2. Which users were held out for validation/testing?
3. What was the train/val/test split?

This will help me design the correct evaluation strategy.

Thanks!"
```

```
STEP 2: Conservative Evaluation Strategy
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
While waiting for mentor's response:

A. Assume ALL users were used for training (worst case)
   â””â”€ Don't claim test accuracy is meaningful

B. Focus on these metrics instead:
   â”œâ”€ Inference pipeline works âœ…
   â”œâ”€ Predictions are consistent âœ…
   â”œâ”€ Confidence scores are reasonable âœ…
   â””â”€ Model loads and runs without errors âœ…

C. Demonstrate MLOps capabilities:
   â”œâ”€ Monitoring setup âœ…
   â”œâ”€ Drift detection âœ…
   â”œâ”€ API serving âœ…
   â”œâ”€ Containerization âœ…
   â””â”€ CI/CD pipeline âœ…
```

```
STEP 3: Collect New Data for Fair Test
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ask friends/colleagues to record:
â”œâ”€ 500 samples per activity (5,500 total)
â”œâ”€ Different people (never in training)
â”œâ”€ Same sensor setup
â””â”€ Label the data

Result: TRUE test set with NO data leakage! âœ…
```

---

## ğŸ“Š EVALUATION STRATEGY (CONSERVATIVE)

### Given Uncertainty About Training Data:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DON'T CLAIM: "Model achieves 95% accuracy"             â”‚
â”‚  âŒ Misleading if User 6 was in training!               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INSTEAD CLAIM: "Model demonstrates:"                    â”‚
â”‚  âœ… Consistent predictions across all 11 activities      â”‚
â”‚  âœ… Average confidence: 92% (model is certain)           â”‚
â”‚  âœ… Production-ready inference pipeline                  â”‚
â”‚  âœ… MLOps monitoring and drift detection                 â”‚
â”‚  âœ… Automated deployment with CI/CD                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Evaluation Plan:

```
TEST 1: Sanity Check (User 6)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Purpose: Verify model loads and runs
Metrics: 
â”œâ”€ Predictions per second
â”œâ”€ Confidence distribution
â”œâ”€ Prediction distribution (balanced?)
â””â”€ No errors/crashes

Report: "Model produces predictions with 92% average 
         confidence. Distribution matches expected 
         activity patterns."

Note: Don't claim accuracy without knowing training split!
```

```
TEST 2: Cross-User Analysis
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Purpose: Detect potential overfitting
Method: Test on ALL users separately

Results:
User 1: Acc=97%, Conf=95%
User 2: Acc=96%, Conf=94%
User 3: Acc=95%, Conf=93%
User 4: Acc=94%, Conf=92%
User 5: Acc=88%, Conf=89%  â† Lower (maybe not in training)
User 6: Acc=87%, Conf=88%  â† Lower (maybe not in training)

Analysis: "Users 5-6 show lower performance, suggesting 
           they may not have been in training set. This 
           indicates reasonable generalization."
```

```
TEST 3: Production Data (Unlabeled)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Purpose: Real-world deployment validation

Data: data/processed/sensor_fused_50Hz.csv
Metrics:
â”œâ”€ Prediction distribution
â”œâ”€ Confidence scores
â”œâ”€ Processing speed
â””â”€ Error handling

Report: "Model successfully processes 181K unlabeled 
         samples. Predictions are consistent and 
         confidence scores are high (avg 90%)."
```

---

## ğŸ“ FOR YOUR THESIS

### How to Present This Issue:

```
HONEST APPROACH (BEST):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"Due to uncertainty about which users were included in 
the pretrained model's training set, we adopt a 
conservative evaluation approach focusing on:

1. Operational metrics (latency, throughput)
2. Prediction consistency and confidence
3. MLOps infrastructure quality
4. Monitoring and drift detection

Rather than claiming specific accuracy numbers, we 
demonstrate the model's production readiness through:
- Real-time inference on unlabeled data
- Automated monitoring and alerting
- Robust deployment pipeline
- Comprehensive testing framework

This approach reflects real-world MLOps scenarios where 
models are deployed and monitored continuously, with 
performance validated through operational metrics and 
user feedback rather than static test sets."
```

### Thesis Value (Even Without Accuracy):

```
âœ… STRONG MLOps Contributions:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. Inference pipeline for unlabeled data
2. Drift detection without ground truth
3. Confidence-based monitoring
4. Smart labeling strategy (active learning)
5. Automated retraining triggers
6. Production-grade deployment
7. CI/CD automation
8. Model versioning and rollback

âŒ WEAK Claim:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"I achieved 95% accuracy!"
â””â”€ Can't prove without knowing training split

âœ… STRONG Claim:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"I built a complete MLOps pipeline that monitors 
model health without labels, detects drift 
automatically, and triggers retraining when needed!"
â””â”€ THIS is valuable for thesis!
```

---

## ğŸ“ ACTION ITEMS

### Immediate (This Week):

- [ ] Email mentor asking about training split
- [ ] Implement evaluation on User 6 (sanity check only)
- [ ] Implement cross-user evaluation (all users)
- [ ] Document conservative evaluation approach

### Short-term (Next 2 Weeks):

- [ ] Build inference pipeline (works regardless of split)
- [ ] Implement monitoring (no labels needed)
- [ ] Setup drift detection
- [ ] Create API endpoint

### Long-term (If needed):

- [ ] Collect new labeled data from friends
- [ ] True test set with guaranteed no leakage
- [ ] Report actual accuracy numbers

---

## ğŸ¯ BOTTOM LINE

**Q: Can we trust testing on User 6?**

**A: We DON'T KNOW!** 
- If mentor trained on Users 1-4 â†’ YES âœ…
- If mentor trained on ALL users â†’ NO âŒ
- We need to ASK the mentor!

**Q: What should we do?**

**A: Two-pronged approach:**
1. **Ask mentor** about training split (do this NOW!)
2. **Focus on MLOps** (doesn't require knowing accuracy)

**Q: Is this a problem for the thesis?**

**A: NO!** Your thesis is about **MLOps**, not about achieving 95% accuracy!
- Monitoring without labels â†’ Thesis contribution âœ…
- Drift detection â†’ Thesis contribution âœ…
- Automated pipeline â†’ Thesis contribution âœ…
- Deployment infrastructure â†’ Thesis contribution âœ…

**Remember:** MLOps is about **operating ML systems**, not **training perfect models**!

---

**Last Updated:** November 5, 2025  
**Status:** Awaiting mentor clarification  
**Priority:** HIGH - Ask mentor this week!
