# Root Cause Analysis: Low Production Accuracy (14-15%)

**Date:** January 9, 2026  
**Status:** ‚úÖ ROOT CAUSE IDENTIFIED  
**Confidence:** HIGH (99%)

---

## Executive Summary

The production accuracy of 14-15% (vs. expected 85%+) is caused by **using IDLE/STATIONARY data for inference**. The `sensor_fused_50Hz.csv` contains data from a user NOT performing any activities (watch lying flat on table), resulting in ~60x less variance than the training data.

**Primary Root Cause:** The production data source (`sensor_fused_50Hz.csv`) contains stationary data with minimal motion, while the model was trained on active movement (11 distinct activities). This is a **DATA CONTENT issue**, not a preprocessing bug.

**The preprocessing code is CORRECT** - it properly:
1. Detects milliG units ‚úÖ
2. Converts to m/s¬≤ with factor 0.00981 ‚úÖ
3. Applies StandardScaler normalization ‚úÖ
4. Creates proper windows ‚úÖ

---

## Two Options for Valid Inference

### Option 1: Collect NEW Garmin Data with Activities (RECOMMENDED)

Since `sensor_fused_50Hz.csv` (March 2025) is from an idle watch, you need to:

1. **Wear the Garmin watch** and perform target activities:
   - ear_rubbing, forehead_rubbing, hair_pulling, hand_scratching
   - hand_tapping, knuckles_cracking, nail_biting, nape_rubbing
   - smoking, sitting, standing

2. **Export the data** from Garmin Connect

3. **Process through the pipeline:**
   ```bash
   # Step 1: Process raw Garmin export
   python src/sensor_data_pipeline.py --input data/raw/YOUR_NEW_EXPORT.xlsx
   
   # Step 2: Preprocess for inference
   python src/preprocess_data.py --input data/processed/sensor_fused_50Hz.csv
   
   # Step 3: Run inference
   python src/run_inference.py
   ```

### Option 2: Use sensor_fused_50Hz.csv AS-IS (For Pipeline Testing Only)

If you just want to **test the pipeline works** (not accuracy):

```bash
# The pipeline will run correctly, but predictions will be unreliable
# because the input data has no meaningful activity patterns
python src/preprocess_data.py --input data/processed/sensor_fused_50Hz.csv
python src/run_inference.py
```

**Expected Result:** ~14% accuracy (near-random) because the model sees "nothing happening"

---

## Note on Timestamps

| Data Source | Timestamps | Actual Date | Notes |
|-------------|------------|-------------|-------|
| sensor_fused_50Hz.csv | 2025-03-24 | March 2025 | Real timestamps, IDLE data |
| garmin_labeled.csv | 2005-05-01 | Unknown | Placeholder dates, has activities |
| all_users_data_labeled.csv | 2005-05-01 | Unknown | Training data, placeholder dates |

The 2005 dates in labeled data are **placeholder timestamps** (common in research datasets). The actual sensor readings are valid - only the timestamps are reset.

---

## Top 10 Ranked Causes

### üî¥ RANK 1: Production Data is IDLE/STATIONARY (CONFIRMED - TRUE ROOT CAUSE)

**Evidence:**
```
Data Source Comparison (Standard Deviation):

                           Ax (m/s¬≤)    Az mean (m/s¬≤)
Training data              6.57         -3.53 (tilted/moving)
sensor_fused_50Hz          0.11         -9.83 (FLAT on table!)

Ratio: Training/Production = 6.57 / 0.11 = ~60x difference!
```

**Analysis:**
- `sensor_fused_50Hz.csv` has Az mean = -9.83 m/s¬≤ (exactly -g = flat on surface)
- Training data has Az mean = -3.53 m/s¬≤ (tilted, typical wrist orientation)
- The production data is from an **IDLE watch on a table**, not a user performing activities
- Timestamp: 2025-03-24 (real data, but no activity)

**Impact:** Model sees "nothing happening" ‚Üí predicts random classes

**Fix Priority:** üî¥ CRITICAL - Collect new data with activities

**Fix:** Record new Garmin data with user performing the 11 target activities

---

### üü¢ RANK 2-10: Previously Suspected Issues (NOW RULED OUT)

After tracing the math, the following were **ruled out** as causes:

| Rank | Suspected Issue | Status | Evidence |
|------|-----------------|--------|----------|
| 2 | Column name mismatch | ‚ùå NOT THE CAUSE | Code handles `Ax` vs `Ax_w` correctly |
| 3 | Unit conversion bug | ‚ùå NOT THE CAUSE | Factor 0.00981 applied correctly |
| 4 | Double normalization | ‚ùå NOT THE CAUSE | Applied once, verified |
| 5 | Scaler mismatch | ‚ùå NOT THE CAUSE | Correct scaler loaded |
| 6 | Gravity removal issue | ‚ùå NOT THE CAUSE | Disabled by default |
| 7 | Window overlap bug | ‚ùå NOT THE CAUSE | Shape correct |
| 8 | Model loading issue | ‚ùå NOT THE CAUSE | Model verified |
| 9 | Evaluation bug | ‚ùå NOT THE CAUSE | Metrics correct |
| 10 | Data type issue | ‚ùå NOT THE CAUSE | Converted to float |

---

## Diagnosis Summary

| # | Cause | Status | Evidence |
|---|-------|--------|----------|
| 1 | **IDLE data used for inference** | **CONFIRMED** | Az=-9.83 m/s¬≤ (flat), std 60x lower |
| 2-10 | Preprocessing bugs | ‚ùå RULED OUT | Code verified correct |

---

## Preprocessing Code Verification

### ‚úÖ Unit Detection (preprocess_data.py lines 99-163)
- Correctly detects milliG when max_abs > 100 ‚úÖ
- Conversion factor 0.00981 matches supervisor's email ‚úÖ

### ‚úÖ Unit Conversion (preprocess_data.py lines 165-209)
- Multiplies accelerometer columns by 0.00981 ‚úÖ
- Validates Az mean ‚âà -9.8 m/s¬≤ after conversion ‚úÖ

### ‚úÖ Gravity Validation
- Az mean in sensor_fused_50Hz.csv: -1001.56 milliG
- After conversion: -1001.56 √ó 0.00981 = **-9.825 m/s¬≤** ‚úÖ
- This confirms data is from watch lying **flat on table** (not on wrist)

### ‚úÖ StandardScaler Normalization (preprocess_data.py lines 468-525)
- Loads correct scaler_mean and scaler_scale from config.json ‚úÖ
- Applies transform correctly ‚úÖ
- The low std (~0.02) is **correct** given low-variance input data

---

## The Math (Verified)

```
sensor_fused_50Hz.csv (raw, milliG):
  Ax std = 11.32 milliG

After milliG ‚Üí m/s¬≤ conversion:
  Ax std = 11.32 √ó 0.00981 = 0.111 m/s¬≤

After StandardScaler normalization:
  Ax std = 0.111 / 6.568 = 0.017  ‚Üê MATCHES production_X.npy!

Training data for comparison:
  Ax_w std = 6.568 m/s¬≤

The normalization is CORRECT.
The problem is the INPUT DATA has no motion variance.
```

---

## Action Plan

### Option 1: Collect NEW Garmin Data with Activities (RECOMMENDED)

**Steps:**
1. **Wear Garmin watch** on wrist
2. **Perform activities** (each for 2-5 minutes):
   - ear_rubbing, forehead_rubbing, hair_pulling
   - hand_scratching, hand_tapping, knuckles_cracking
   - nail_biting, nape_rubbing, smoking
   - sitting, standing
3. **Export data** from Garmin Connect (Excel/CSV format)
4. **Process through pipeline:**
   ```bash
   # Process raw export
   python src/sensor_data_pipeline.py --input data/raw/NEW_ACTIVITY_DATA.xlsx
   
   # Preprocess for inference  
   python src/preprocess_data.py --input data/processed/sensor_fused_50Hz.csv
   
   # Run inference
   python src/run_inference.py
   ```
5. **Expected accuracy:** 70-85% (similar to training)

### Option 2: Pipeline Test Only (Current IDLE Data)

**Use Case:** Verify the pipeline runs correctly (NOT for accuracy evaluation)

```bash
# Run with current idle data - pipeline will work, accuracy will be low
python src/preprocess_data.py --input data/processed/sensor_fused_50Hz.csv
python src/run_inference.py
```

**Expected Result:** 
- Pipeline completes successfully ‚úÖ
- Accuracy ~14% (near-random) ‚ö†Ô∏è
- This is EXPECTED because input has no activity patterns

### Why garmin_labeled.csv Cannot Be Used

The `garmin_labeled.csv` file has timestamps from 2005 (placeholder dates) and is part of a research dataset, not real production data. For a valid production inference test, you need:
- **Real Garmin data** from your own watch
- **Actual activities** being performed
- **Recent timestamps** (2025+)

---

## Conclusion

The 14-15% accuracy is caused by using **IDLE/STATIONARY data** for inference. The `sensor_fused_50Hz.csv` file contains data from a watch lying flat on a table (Az = -9.83 m/s¬≤ = pure gravity), with no user activity.

**The preprocessing code is CORRECT.** The issue is the data content:

| Data Source | Date | Ax std (m/s¬≤) | Az mean (m/s¬≤) | Status |
|-------------|------|---------------|----------------|--------|
| Training data | 2005* | 6.57 | -3.53 | ‚úÖ Active movement |
| sensor_fused_50Hz.csv | 2025-03-24 | 0.11 | -9.83 | ‚ùå IDLE (flat) |

*2005 dates are placeholder timestamps in research data

**Solution:** Collect NEW Garmin data with user actively performing the 11 target activities.

---

## Script Verification Summary

| Script | Component | Status |
|--------|-----------|--------|
| `src/preprocess_data.py` | Unit detection (milliG vs m/s¬≤) | ‚úÖ CORRECT |
| `src/preprocess_data.py` | Conversion factor (0.00981) | ‚úÖ CORRECT |
| `src/preprocess_data.py` | StandardScaler normalization | ‚úÖ CORRECT |
| `src/preprocess_data.py` | Windowing (200 samples, 50% overlap) | ‚úÖ CORRECT |
| `src/run_inference.py` | Model loading | ‚úÖ CORRECT |
| `src/run_inference.py` | Batch inference | ‚úÖ CORRECT |
| `src/evaluate_predictions.py` | Metrics computation | ‚úÖ CORRECT |

---

## Supervisor Confirmation (Dec 3, 2025)

From Oleh Ugonna:
> "The accelerometer data was converted from milliG to m/s^2. Here is the conversion factor:
> conversion_factor = 0.00981
> The accelerometer values from the unlabeled data are still in milliG and need to be multiplied by the conversion factor."

**Status:** Conversion factor is correctly implemented in `preprocess_data.py` (line 101).

---

## Appendix: Key Evidence

| File | Date | Units | Status |
|------|------|-------|--------|
| `sensor_fused_50Hz.csv` | 2025-03-24 | milliG | ‚ö†Ô∏è Real date, IDLE data |
| `garmin_labeled.csv` | 2005* | m/s¬≤ | Research dataset, not production |
| `all_users_data_labeled.csv` | 2005* | m/s¬≤ | Training data |
| `config.json` | - | - | ‚úÖ Correct scaler |
| `production_X.npy` | 2026-01-06 | normalized | ‚ö†Ô∏è From IDLE data |

*Placeholder timestamps from research dataset
