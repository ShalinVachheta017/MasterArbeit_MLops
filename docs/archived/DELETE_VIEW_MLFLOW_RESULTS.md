# ğŸ¯ VIEW YOUR MLFLOW EXPERIMENTS NOW!

## âš¡ Quick Start (2 steps)

### Step 1: Open NEW PowerShell Terminal
```powershell
# In a NEW terminal (don't use the one with the pipeline run)
cd "D:\study apply\ML Ops\MasterArbeit_MLops"
```

### Step 2: Start MLflow UI
```powershell
mlflow ui
```

**Output should say:**
```
INFO: Uvicorn running on http://127.0.0.1:5000
```

### Step 3: Open in Browser
```
http://localhost:5000
```

---

## âœ… WHAT YOU'LL SEE

### Experiment List:
```
inference-production          â† Your experiment
â”œâ”€ Run: 2025-12-12 17:51:05  â† Your pipeline run
â”‚  â”œâ”€ Duration: 4 seconds
â”‚  â”œâ”€ Metrics:
â”‚  â”‚  â”œâ”€ model_params: 499131
â”‚  â”‚  â”œâ”€ n_windows: 1815
â”‚  â”‚  â”œâ”€ avg_confidence: 0.52
â”‚  â”‚  â”œâ”€ count_forehead_rubbing: 1799
â”‚  â”‚  â”œâ”€ count_nape_rubbing: 9
â”‚  â”‚  â””â”€ ... (more metrics)
â”‚  â””â”€ Artifacts:
â”‚     â””â”€ predictions_20251212_175115.csv âœ…
```

---

## ğŸ“Š METRICS YOU'LL SEE

| Metric | Value | Meaning |
|--------|-------|---------|
| `model_params` | 499,131 | Model size |
| `n_windows` | 1,815 | Windows processed |
| `timesteps` | 200 | Time points per window |
| `channels` | 6 | Sensor channels |
| `avg_confidence` | 0.52 | Average prediction confidence |
| `std_confidence` | 0.27 | Confidence variation |
| `count_forehead_rubbing` | 1,799 | Most common activity |
| `count_nape_rubbing` | 9 | Second activity |
| `count_standing` | 2 | Other activities |

---

## ğŸ ARTIFACTS YOU'LL SEE

**Prediction Files:**
```
predictions_20251212_175115.csv
â”œâ”€ window_id: 0, 1, 2, ...
â”œâ”€ predicted_activity: forehead_rubbing
â”œâ”€ confidence: 0.52, 0.48, ...
â””â”€ confidence_level: UNCERTAIN, LOW, ...
```

**Metadata:**
```
predictions_20251212_175115_metadata.json
â”œâ”€ total_windows: 1815
â”œâ”€ uncertain_count: 952
â”œâ”€ avg_confidence: 0.52
â””â”€ activity_distribution: {...}
```

**Probabilities:**
```
predictions_20251212_175115_probs.npy
â””â”€ (1815, 11) matrix of class probabilities
```

---

## ğŸ–¼ï¸ UI Layout

```
Top Navigation:
  [Experiments] [Runs] [Compare Runs]

Left Sidebar:
  âœ… Experiments
    â””â”€ inference-production (ACTIVE)
       â””â”€ Runs (1)
          â””â”€ 2025-12-12 17:51:05 (Success)

Main Panel:
  Run Overview:
  â”œâ”€ Status: Completed âœ…
  â”œâ”€ Start time: 2025-12-12 17:51:05
  â”œâ”€ Duration: 4 seconds
  â”œâ”€ Parameters (8): model_path, batch_size, ...
  â”œâ”€ Metrics (10): avg_confidence, std_confidence, ...
  â””â”€ Artifacts (3): CSV, JSON, NPY files

Tabs:
  â”œâ”€ Overview (current)
  â”œâ”€ Metrics (line charts)
  â”œâ”€ Artifacts (download files)
  â””â”€ Metadata
```

---

## ğŸ”— URLS

| Page | URL |
|------|-----|
| Home | http://localhost:5000 |
| Experiments | http://localhost:5000/experiments |
| Your Experiment | http://localhost:5000/experiments/950614147457743858 |
| Your Run | http://localhost:5000/experiments/950614147457743858/runs/63f4a91bc5924b5cafb4bcb028f69d6b |

---

## ğŸ¯ THINGS TO EXPLORE

### 1. View Metrics Over Time
- Click "Metrics" tab
- See confidence distribution
- View activity counts as bar chart

### 2. Download Artifacts
- Click "Artifacts" tab
- Download CSV file
- Import to Excel or Python

### 3. Compare Multiple Runs
- Run pipeline again (tomorrow)
- Both runs appear in list
- Compare metrics side-by-side

### 4. Export Data
- Right-click on run
- Export to CSV
- Share with mentor

---

## ğŸ†˜ TROUBLESHOOTING

### MLflow UI Won't Open

**Problem:** Browser shows "can't reach localhost:5000"

**Solution:**
```powershell
# Check if port 5000 is busy
netstat -ano | grep :5000

# If busy, use different port
mlflow ui --port 5001
# Then open: http://localhost:5001
```

### No Experiments Shown

**Problem:** "Experiments" page is empty

**Solution:**
```powershell
# Verify mlruns folder exists
ls mlruns/

# If empty, re-run pipeline
python src/run_inference.py
```

### Artifacts Not Showing

**Problem:** Artifacts tab is empty

**Solution:**
```powershell
# Check artifacts were saved
ls data/prepared/predictions/

# If empty, pipeline didn't complete
# Re-run and check for errors
```

---

## ğŸ“± MOBILE ACCESS

To view MLflow from phone/tablet:

```powershell
# Find your computer's IP
ipconfig

# Get IPv4 address (e.g., 192.168.1.100)

# Start MLflow with host binding
mlflow ui --host 0.0.0.0 --port 5000

# From phone, open:
http://192.168.1.100:5000
```

---

## ğŸ’¾ BACKUP YOUR EXPERIMENTS

```powershell
# MLflow data is in mlruns/ folder
# To backup:
Copy-Item -Path "mlruns" -Destination "mlruns_backup_20251212" -Recurse

# To restore:
Copy-Item -Path "mlruns_backup_20251212" -Destination "mlruns" -Recurse
```

---

## ğŸ”„ RUN PIPELINE AGAIN

To track new experiments:

```powershell
# This will create NEW run automatically
python src/sensor_data_pipeline.py
python src/preprocess_data.py --calibrate
python src/run_inference.py
python src/evaluate_predictions.py

# New run appears in MLflow UI automatically âœ…
```

---

## ğŸ“ˆ NEXT STEPS

1. âœ… MLflow UI open
2. â†’ View your experiment
3. â†’ Check metrics and artifacts
4. â†’ Download predictions CSV
5. â†’ Share results with mentor
6. â†’ Run again tomorrow for trend tracking

---

**ğŸ‰ Your experiments are now being tracked in MLflow!**

**Next Command:**
```powershell
mlflow ui
```

**Then Open:**
```
http://localhost:5000
```
