# FINAL THESIS IMPLEMENTATION ROADMAP - 3 PATHWAYS
## HAR Wearable Sensor MLOps Pipeline - Decision Document

**Created:** January 6, 2026  
**Thesis Month:** 3-4 (CI/CD, Monitoring, Retraining Phase)  
**Current Status:** Inference pipeline working, Retraining pipeline needed  

---

## ğŸ“Š CURRENT SITUATION SUMMARY

### What We Have âœ…
- **Pretrained Model:** 1D-CNN-BiLSTM (499K params) trained on ADAMSense
- **Inference Pipeline:** Raw Garmin â†’ Preprocess â†’ Model â†’ Predictions
- **Model Versioning:** MLflow/DVC tracking in place
- **Research Insights:** 150+ papers analyzed via NotebookLM

### What's Missing âŒ
- **Retraining Pipeline:** No mechanism to update model with new data
- **Drift Detection:** No monitoring for data/concept drift
- **CI/CD:** No automated deployment pipeline
- **Lab-to-Life Bridge:** Model trained on lab data, deployed on Garmin (49% â†’ 87% gap)

---

## ğŸ›¤ï¸ THREE PATHWAYS TO COMPLETE THESIS

---

# PATH A: Research Paper-Based Solutions (Academic Focus)
## *Implement Domain Adaptation from Literature*

### Core Methodology: AdaBN + UDA
Based on ICTH_16 and 150+ paper insights, implement:

#### 1. **AdaBN (Adaptive Batch Normalization)** - Simplest UDA Method
```
How it works:
- Freeze all model weights during inference
- Compute target-specific Batch Normalization statistics (mean/variance)
- Update only BN layers with Garmin data statistics
- No labels required from target domain

Implementation:
1. Load pretrained model
2. Forward pass through Garmin data (inference mode but collecting BN stats)
3. Update running_mean and running_var in BN layers
4. Use updated model for final predictions
```

**Code Location:** `src/domain_adaptation/adabn.py`

#### 2. **Contrastive Learning** (Optional Advanced)
```
From papers:
- Create positive pairs (same activity, different time)
- Create negative pairs (different activities)
- Learn domain-invariant representations
```

#### 3. **MMD/DANN** (If AdaBN insufficient)
- Maximum Mean Discrepancy for distribution matching
- Domain Adversarial Neural Networks for feature alignment

### Pros & Cons
| Pros | Cons |
|------|------|
| âœ… Academically rigorous | âŒ Complex to implement |
| âœ… Novel thesis contribution | âŒ May need hyperparameter tuning |
| âœ… Addresses lab-to-life gap | âŒ No production-ready patterns |
| âœ… Paper citations ready | âŒ Limited MLOps focus |

### Implementation Effort: **4-6 weeks**

---

# PATH B: Practical MLOps Pipeline (Industry Focus)
## *Based on Research Answers + Best Practices*

### Core Components (From NotebookLM Research)

#### 1. **Drift Detection System**
```python
# KS-Test for Feature Drift (No Labels Required)
from scipy.stats import ks_2samp

def detect_drift(baseline_data, new_data, threshold=0.05):
    """
    Kolmogorov-Smirnov test for each feature
    Returns: dict of {feature: (statistic, p_value, drifted)}
    """
    results = {}
    for feature in baseline_data.columns:
        stat, p_val = ks_2samp(baseline_data[feature], new_data[feature])
        results[feature] = {
            'statistic': stat,
            'p_value': p_val,
            'drifted': p_val < threshold
        }
    return results
```

#### 2. **Combined Retraining Triggers**
```
From ICTH_16 Paper Research:
â”œâ”€â”€ Drift-Based: KS-test detects significant distribution shift
â”œâ”€â”€ Performance-Based: Prediction entropy > threshold (low confidence)  
â”œâ”€â”€ Scheduled: Weekly/monthly automatic retraining
â””â”€â”€ Human-Initiated: Manual trigger for new labeled data

Recommendation: Use ALL triggers with priority:
1. Performance drop â†’ immediate retraining
2. Drift detected â†’ queue retraining
3. Scheduled â†’ background retraining
```

#### 3. **EWC (Elastic Weight Consolidation)**
```
Prevents catastrophic forgetting during incremental retraining:
- Compute Fisher Information Matrix on old data
- Add regularization term to loss function
- Protects important weights from changing too much

Loss = CrossEntropy + Î» * Î£ F_i * (Î¸ - Î¸_old)Â²
```

#### 4. **Cross-Validation Strategy**
```
From ICTH_16: 6 volunteers fine-tuning improved 49% â†’ 87%

For Retraining Pipeline:
â”œâ”€â”€ Collect labeled data from users (or pseudo-labels)
â”œâ”€â”€ 5-Fold CV on new data to validate model updates
â”œâ”€â”€ Compare against baseline model
â””â”€â”€ Deploy only if improvement > threshold
```

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRODUCTION MLOPS PIPELINE                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Raw Data â”‚â”€â”€â”€â”€â–¶â”‚ Preprocessâ”‚â”€â”€â”€â”€â–¶â”‚ Inference â”‚           â”‚
â”‚  â”‚ (Garmin) â”‚     â”‚   Stage   â”‚     â”‚  Model    â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                          â”‚                  â”‚
â”‚                                          â–¼                  â”‚
â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚                                   â”‚Predictionsâ”‚              â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                         â”‚                   â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚       â”‚            MONITORING LAYER     â”‚               â”‚   â”‚
â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”          â”‚   â”‚
â”‚       â”‚  â”‚ Drift   â”‚  â”‚Scheduledâ”‚  â”‚Entropy â”‚          â”‚   â”‚
â”‚       â”‚  â”‚Detector â”‚  â”‚ Trigger â”‚  â”‚Monitor â”‚          â”‚   â”‚
â”‚       â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â”‚   â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚            â”‚           â”‚                    â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                            â”‚                                â”‚
â”‚                            â–¼                                â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚  RETRAINING  â”‚                         â”‚
â”‚                    â”‚   PIPELINE   â”‚                         â”‚
â”‚                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â”‚
â”‚                    â”‚ â€¢ Load Data  â”‚                         â”‚
â”‚                    â”‚ â€¢ K-Fold CV  â”‚                         â”‚
â”‚                    â”‚ â€¢ EWC Loss   â”‚                         â”‚
â”‚                    â”‚ â€¢ Evaluate   â”‚                         â”‚
â”‚                    â”‚ â€¢ Version    â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pros & Cons
| Pros | Cons |
|------|------|
| âœ… Production-ready patterns | âŒ Less academically novel |
| âœ… Industry-standard MLOps | âŒ Doesn't solve domain shift directly |
| âœ… Practical for thesis demo | âŒ May need labeled data |
| âœ… Clear implementation path | âŒ Performance may plateau |

### Implementation Effort: **3-4 weeks**

---

# PATH C: Reference Implementation (From GitHub Repos)
## *Adapt Vehicle Insurance / YT-Capstone Patterns*

### Learning from Your Previous Projects

#### From `Vehicle-Insurance-DataPipeline-MLops-`
```
ğŸ“¦ Key Components to Adapt:
â”œâ”€â”€ src/components/
â”‚   â”œâ”€â”€ data_ingestion.py      â†’ Load new Garmin data
â”‚   â”œâ”€â”€ data_validation.py     â†’ Schema checks + drift detection
â”‚   â”œâ”€â”€ data_transformation.py â†’ Preprocessing pipeline
â”‚   â”œâ”€â”€ model_trainer.py       â†’ Retraining logic
â”‚   â”œâ”€â”€ model_evaluation.py    â†’ Compare with production model
â”‚   â””â”€â”€ model_pusher.py        â†’ Deploy to S3/local
â”‚
â”œâ”€â”€ src/entity/
â”‚   â”œâ”€â”€ config_entity.py       â†’ Configuration dataclasses
â”‚   â””â”€â”€ artifact_entity.py     â†’ Pipeline artifacts tracking
â”‚
â”œâ”€â”€ src/pipeline/
â”‚   â”œâ”€â”€ training_pipeline.py   â†’ Orchestrate full retraining
â”‚   â””â”€â”€ prediction_pipeline.py â†’ Inference pipeline (already have)
â”‚
â””â”€â”€ CI/CD:
    â””â”€â”€ .github/workflows/     â†’ GitHub Actions for automation
```

#### Key Pattern: Model Evaluation Gate
```python
# From Vehicle Insurance project
class ModelEvaluation:
    def start_model_evaluation(self, data_ingestion_artifact, model_trainer_artifact):
        """
        Compares newly trained model with production model
        Only promotes if performance improves
        """
        if not model_evaluation_artifact.is_model_accepted:
            logging.info("Model not accepted - keeping production version")
            return None
        
        # Push new model to production
        model_pusher_artifact = self.start_model_pusher(model_evaluation_artifact)
```

#### From `YT-Capstone-Project`
```
ğŸ“¦ Additional Components:
â”œâ”€â”€ MLflow Integration
â”‚   â”œâ”€â”€ DagsHub for remote tracking
â”‚   â”œâ”€â”€ Model Registry (Staging â†’ Production)
â”‚   â””â”€â”€ Experiment comparison
â”‚
â”œâ”€â”€ CI/CD Pipeline
â”‚   â”œâ”€â”€ tests/test_model.py    â†’ Model validation tests
â”‚   â”œâ”€â”€ scripts/promote_model.py â†’ Stage â†’ Production promotion
â”‚   â””â”€â”€ Prometheus/Grafana     â†’ Monitoring (optional)
â”‚
â””â”€â”€ Deployment
    â”œâ”€â”€ Docker + ECR
    â”œâ”€â”€ EKS for scaling
    â””â”€â”€ GitHub Actions automation
```

#### From `house-price-predictor_MLops_U`
```
ğŸ“¦ Streamlined Patterns:
â”œâ”€â”€ src/data/run_processing.py  â†’ Clean data processing script
â”œâ”€â”€ src/features/engineer.py    â†’ Feature engineering pipeline
â”œâ”€â”€ src/models/train_model.py   â†’ Model training with MLflow
â”œâ”€â”€ src/api/
â”‚   â”œâ”€â”€ main.py                 â†’ FastAPI endpoints
â”‚   â”œâ”€â”€ inference.py            â†’ Prediction logic
â”‚   â””â”€â”€ schemas.py              â†’ Pydantic models
â”‚
â””â”€â”€ docker-compose.yaml         â†’ Multi-container deployment
```

### Proposed HAR Pipeline Structure
```
MasterArbeit_MLops/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py        # Load Garmin CSV/real-time
â”‚   â”‚   â”œâ”€â”€ data_validation.py       # Schema + Drift Detection
â”‚   â”‚   â”œâ”€â”€ data_transformation.py   # Sensor preprocessing
â”‚   â”‚   â”œâ”€â”€ model_trainer.py         # Fine-tuning with EWC
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py      # Compare vs production
â”‚   â”‚   â””â”€â”€ model_pusher.py          # Version & deploy
â”‚   â”‚
â”‚   â”œâ”€â”€ entity/
â”‚   â”‚   â”œâ”€â”€ config_entity.py         # DataIngestionConfig, etc.
â”‚   â”‚   â””â”€â”€ artifact_entity.py       # DataIngestionArtifact, etc.
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ inference_pipeline.py    # Current: Garmin â†’ Prediction
â”‚   â”‚   â””â”€â”€ training_pipeline.py     # NEW: Retraining orchestration
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ drift_detector.py        # KS-test implementation
â”‚   â”‚   â””â”€â”€ retraining_triggers.py   # Trigger logic
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ main_utils.py            # Helper functions
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ schema.yaml                  # Data schema definition
â”‚   â””â”€â”€ model_config.yaml            # Model hyperparameters
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.training
â”‚   â””â”€â”€ Dockerfile.inference
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci_cd.yaml                   # GitHub Actions pipeline
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_model_loading.py
    â””â”€â”€ test_drift_detection.py
```

### Pros & Cons
| Pros | Cons |
|------|------|
| âœ… Proven patterns you've used | âŒ Adapting for sensor data |
| âœ… Quick to implement | âŒ May not address domain shift |
| âœ… Complete MLOps structure | âŒ Extra work to integrate research |
| âœ… GitHub Actions ready | âŒ Need to adapt from tabular to time-series |

### Implementation Effort: **2-3 weeks** (structure), **+2 weeks** (integration)

---

## ğŸ¯ RECOMMENDATION: HYBRID APPROACH

### Best Strategy for Your Thesis

**Combine Path B + Path C with Path A as optional enhancement**

```
Week 1-2: Set up MLOps Structure (Path C)
â”œâ”€â”€ Create entity/component structure
â”œâ”€â”€ Adapt from Vehicle Insurance patterns
â”œâ”€â”€ Set up basic training pipeline skeleton

Week 3-4: Implement Monitoring (Path B)
â”œâ”€â”€ KS-test drift detection
â”œâ”€â”€ Entropy-based confidence monitoring
â”œâ”€â”€ Retraining triggers

Week 5-6: Add Retraining Pipeline (Path B + C)
â”œâ”€â”€ Fine-tuning with EWC (prevents forgetting)
â”œâ”€â”€ K-Fold CV for validation
â”œâ”€â”€ Model evaluation gate

Week 7-8: CI/CD & Deployment (Path C)
â”œâ”€â”€ GitHub Actions workflow
â”œâ”€â”€ Docker containerization
â”œâ”€â”€ MLflow model registry

Week 9-10 (Optional): Domain Adaptation (Path A)
â”œâ”€â”€ Implement AdaBN if time permits
â”œâ”€â”€ Test on Garmin data
â”œâ”€â”€ Compare with baseline

Final: Documentation & Thesis Writing
â”œâ”€â”€ Document all components
â”œâ”€â”€ Create architecture diagrams
â”œâ”€â”€ Write thesis chapters
```

---

## ğŸ“ FILES TO CREATE NEXT

### Priority 1: Pipeline Structure
```
src/components/data_ingestion.py
src/components/data_validation.py  
src/entity/config_entity.py
src/entity/artifact_entity.py
src/pipeline/training_pipeline.py
```

### Priority 2: Monitoring
```
src/monitoring/drift_detector.py
src/monitoring/retraining_triggers.py
```

### Priority 3: CI/CD
```
.github/workflows/ci_cd.yaml
docker-compose.yaml (update)
```

---

## ğŸ“š KEY RESEARCH REFERENCES

| Concept | Source | Use Case |
|---------|--------|----------|
| AdaBN | Multiple UDA papers | Simple domain adaptation |
| KS-Test | Statistical literature | Drift detection without labels |
| EWC | Kirkpatrick et al. 2017 | Prevent catastrophic forgetting |
| 6-volunteer fine-tuning | ICTH_16 | Validation benchmark (49%â†’87%) |
| Combined triggers | ICTH_16 + others | Retraining decision logic |

---

## âœ… NEXT ACTION

**Tell me which path or combination you want to start with, and I'll create the implementation files.**

Options:
1. **"Start with Path B+C"** â†’ I'll create the MLOps structure + monitoring
2. **"Start with Path A"** â†’ I'll implement AdaBN first
3. **"Full hybrid"** â†’ I'll create complete structure with all components
4. **"Just CI/CD"** â†’ Focus on deployment pipeline first

---

*Document maintained as thesis roadmap. Update as implementation progresses.*
