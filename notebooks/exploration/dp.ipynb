{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57065793",
   "metadata": {},
   "source": [
    "\n",
    "# 0) Notebook title & overview\n",
    "\n",
    "**Markdown**\n",
    "\n",
    "> # Garmin Wearable — Simple Accel+Gyro Processing (Easy Mode)\n",
    ">\n",
    "> **Goal:** turn two raw Excel files (accelerometer & gyroscope) with batched samples into a single, clean **50 Hz** time series with columns:\n",
    "> `timestamp, timestamp_ms, Ax, Ay, Az, Gx, Gy, Gz`.\n",
    ">\n",
    "> **Key ideas:**\n",
    ">\n",
    "> 1. Parse list-like columns → 2) explode to one row per sample → 3) build true timestamps → 4) align accel↔gyro by nearest time → 5) resample to exact 50 Hz.\n",
    ">\n",
    "> We keep everything **UTC**, avoid clever abstractions, and comment every step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f6f21",
   "metadata": {},
   "source": [
    "# 1) Imports & file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0ed3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json, ast\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIR = Path.cwd()\n",
    "BASE_DIR = CURRENT_DIR.parent\n",
    "\n",
    "# paths to your files inside \"data\"\n",
    "ACCEL_PATH = BASE_DIR / \"data\" / \"2025-03-23-15-23-10-accelerometer_data.xlsx\"\n",
    "GYRO_PATH  = BASE_DIR / \"data\" / \"2025-03-23-15-23-10-gyroscope_data.xlsx\"\n",
    "\n",
    "TARGET_HZ = 50                 # resample target (Hz)\n",
    "MERGE_TOLERANCE_MS = 1       # max accel↔gyro time gap allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93527706",
   "metadata": {},
   "source": [
    "# 2) Load raw Excel & peek\n",
    "\n",
    "> We read both Excel files as-is to see the original column names.\n",
    "> Many Garmin exports have:\n",
    ">\n",
    "> * `timestamp` (date string)\n",
    "> * `timestamp_ms` (base ms offset)\n",
    "> * `sample_time_offset` (list of per-sample ms within the row)\n",
    "> * per-axis arrays like `calibrated_accel_x|y|z` or already `x|y|z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5e8aeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accel data read successfully\n",
      "                 timestamp  timestamp_ms  \\\n",
      "0  03/24/2025, 07:52:19 AM           766   \n",
      "1  03/24/2025, 07:52:20 AM            23   \n",
      "2  03/24/2025, 07:52:20 AM           271   \n",
      "3  03/24/2025, 07:52:20 AM           518   \n",
      "4  03/24/2025, 07:52:20 AM           767   \n",
      "\n",
      "                                  sample_time_offset  \\\n",
      "0  [\"0\",\"10\",\"29\",\"38\",\"48\",\"57\",\"66\",\"77\",\"85\",\"...   \n",
      "1  [\"0\",\"9\",\"19\",\"28\",\"38\",\"48\",\"57\",\"67\",\"77\",\"8...   \n",
      "2  [\"0\",\"10\",\"19\",\"29\",\"38\",\"47\",\"58\",\"66\",\"76\",\"...   \n",
      "3  [\"0\",\"11\",\"20\",\"29\",\"39\",\"48\",\"58\",\"68\",\"77\",\"...   \n",
      "4  [\"0\",\"9\",\"19\",\"29\",\"38\",\"57\",\"66\",\"76\",\"85\",\"9...   \n",
      "\n",
      "                                  calibrated_accel_x  \\\n",
      "0  [\"-62.48186\",\"-27.60828\",\"-95.41802\",\"-155.478...   \n",
      "1  [\"-178.7271\",\"-161.2903\",\"-133.1977\",\"-124.479...   \n",
      "2  [\"-81.85607\",\"-92.51189\",\"-101.2303\",\"-112.854...   \n",
      "3  [\"-79.91866\",\"-134.1664\",\"-75.07510\",\"-51.8260...   \n",
      "4  [\"-90.57446\",\"-102.1990\",\"-91.54318\",\"-101.230...   \n",
      "\n",
      "                                  calibrated_accel_y  \\\n",
      "0  [\"-758.6971\",\"-984.1958\",\"-1240.532\",\"-1338.82...   \n",
      "1  [\"-1360.991\",\"-1342.681\",\"-1269.442\",\"-1171.14...   \n",
      "2  [\"-1140.310\",\"-1056.471\",\"-967.8134\",\"-805.917...   \n",
      "3  [\"-937.9397\",\"-780.8616\",\"-564.9995\",\"-405.030...   \n",
      "4  [\"-722.0777\",\"-764.4792\",\"-776.0432\",\"-777.006...   \n",
      "\n",
      "                                  calibrated_accel_z  \n",
      "0  [\"-1097.585\",\"-1221.784\",\"-1086.742\",\"-957.614...  \n",
      "1  [\"-777.2302\",\"-619.5170\",\"-460.8181\",\"-345.490...  \n",
      "2  [\"-254.8053\",\"-147.3632\",\"-53.72105\",\"-31.0497...  \n",
      "3  [\"-22.17841\",\"12.32134\",\"-84.27797\",\"-139.4776...  \n",
      "4  [\"-574.1744\",\"-697.3879\",\"-701.3307\",\"-706.259...  \n",
      "gyro data read successfully\n",
      "                 timestamp  timestamp_ms  \\\n",
      "0  03/24/2025, 07:52:19 AM           795   \n",
      "1  03/24/2025, 07:52:20 AM            52   \n",
      "2  03/24/2025, 07:52:20 AM           300   \n",
      "3  03/24/2025, 07:52:20 AM           548   \n",
      "4  03/24/2025, 07:52:20 AM           796   \n",
      "\n",
      "                                  sample_time_offset  \\\n",
      "0  [\"0\",\"9\",\"19\",\"38\",\"48\",\"57\",\"67\",\"76\",\"85\",\"9...   \n",
      "1  [\"0\",\"9\",\"19\",\"28\",\"38\",\"48\",\"57\",\"67\",\"76\",\"8...   \n",
      "2  [\"0\",\"9\",\"19\",\"29\",\"38\",\"48\",\"57\",\"66\",\"76\",\"8...   \n",
      "3  [\"0\",\"9\",\"18\",\"28\",\"38\",\"47\",\"57\",\"67\",\"76\",\"8...   \n",
      "4  [\"0\",\"9\",\"19\",\"28\",\"47\",\"56\",\"66\",\"76\",\"85\",\"9...   \n",
      "\n",
      "                                   calibrated_gyro_x  \\\n",
      "0  [\"39.15614\",\"32.96125\",\"22.04125\",\"1.041086\",\"...   \n",
      "1  [\"-24.26378\",\"-35.91878\",\"-44.66883\",\"-50.3738...   \n",
      "2  [\"-49.46386\",\"-51.45886\",\"-49.60395\",\"-43.0239...   \n",
      "3  [\"-46.17395\",\"-45.54395\",\"-37.45898\",\"-25.1389...   \n",
      "4  [\"2.160977\",\"1.005977\",\"1.531018\",\"1.986018\",\"...   \n",
      "\n",
      "                                   calibrated_gyro_y  \\\n",
      "0  [\"-7.520049\",\"-10.77502\",\"-9.620019\",\"-4.79006...   \n",
      "1  [\"-12.10503\",\"-11.82503\",\"-11.30004\",\"-9.90004...   \n",
      "2  [\"-9.515048\",\"-7.205049\",\"-4.720075\",\"-2.02507...   \n",
      "3  [\"-7.835075\",\"-7.310075\",\"-2.620082\",\"-1.50008...   \n",
      "4  [\"3.259907\",\"3.924907\",\"3.679918\",\"4.589918\",\"...   \n",
      "\n",
      "                                   calibrated_gyro_z  \n",
      "0  [\"7.881836\",\"7.742001\",\"12.78200\",\"2.981754\",\"...  \n",
      "1  [\"-0.3430405\",\"-1.078040\",\"-1.533123\",\"-2.1631...  \n",
      "2  [\"-1.743164\",\"-2.723164\",\"-3.773308\",\"-4.08830...  \n",
      "3  [\"-1.253308\",\"-2.198308\",\"-2.268349\",\"-3.56334...  \n",
      "4  [\"-10.80841\",\"-11.50841\",\"-10.73835\",\"-9.47834...  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    accel_raw = pd.read_excel(ACCEL_PATH) # type: ignore\n",
    "    print(\"accel data read successfully\")\n",
    "    print(accel_raw.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error reading accel data: {e}\") \n",
    "\n",
    "try:\n",
    "    gyro_raw = pd.read_excel(GYRO_PATH)   # type: ignore\n",
    "    print(\"gyro data read successfully\")\n",
    "    print(gyro_raw.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error reading gyro data: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbfed15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in accel: []\n",
      "Missing in gyro : []\n"
     ]
    }
   ],
   "source": [
    "accel_map = {\n",
    "    \"calibrated_accel_x\": \"x\",\n",
    "    \"calibrated_accel_y\": \"y\",\n",
    "    \"calibrated_accel_z\": \"z\"\n",
    "}\n",
    "for k,v in accel_map.items():\n",
    "    if k in accel_raw.columns:\n",
    "        accel_raw = accel_raw.rename(columns={k:v})\n",
    "\n",
    "# For gyro\n",
    "gyro_map = {\n",
    "    \"calibrated_gyro_x\": \"x\",\n",
    "    \"calibrated_gyro_y\": \"y\",\n",
    "    \"calibrated_gyro_z\": \"z\"\n",
    "}\n",
    "for k,v in gyro_map.items():\n",
    "    if k in gyro_raw.columns:\n",
    "        gyro_raw = gyro_raw.rename(columns={k:v})\n",
    "\n",
    "# Check we have the basics we need\n",
    "needed = [\"timestamp\",\"timestamp_ms\",\"sample_time_offset\",\"x\",\"y\",\"z\"]\n",
    "missing_acc = [c for c in needed if c not in accel_raw.columns]\n",
    "missing_gyr = [c for c in needed if c not in gyro_raw.columns]\n",
    "print(\"Missing in accel:\", missing_acc)\n",
    "print(\"Missing in gyro :\", missing_gyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555dbe29",
   "metadata": {},
   "source": [
    "# 3) Normalize column names to a simple schema\n",
    "\n",
    "\n",
    "\n",
    "> To make later steps easy, we normalize headers:\n",
    ">\n",
    "> * Accelerometer → `x, y, z`\n",
    "> * Gyroscope     → `x, y, z`\n",
    ">   (We’ll add the `A`/`G` prefixes **after** exploding.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f08ba0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in accel: []\n",
      "Missing in gyro : []\n"
     ]
    }
   ],
   "source": [
    "accel_map = {\n",
    "    \"calibrated_accel_x\": \"x\",\n",
    "    \"calibrated_accel_y\": \"y\",\n",
    "    \"calibrated_accel_z\": \"z\"\n",
    "}\n",
    "for k,v in accel_map.items():\n",
    "    if k in accel_raw.columns:\n",
    "        accel_raw = accel_raw.rename(columns={k:v})\n",
    "\n",
    "# For gyro\n",
    "gyro_map = {\n",
    "    \"calibrated_gyro_x\": \"x\",\n",
    "    \"calibrated_gyro_y\": \"y\",\n",
    "    \"calibrated_gyro_z\": \"z\"\n",
    "}\n",
    "for k,v in gyro_map.items():\n",
    "    if k in gyro_raw.columns:\n",
    "        gyro_raw = gyro_raw.rename(columns={k:v})\n",
    "\n",
    "# Check we have the basics we need\n",
    "needed = [\"timestamp\",\"timestamp_ms\",\"sample_time_offset\",\"x\",\"y\",\"z\"]\n",
    "missing_acc = [c for c in needed if c not in accel_raw.columns]\n",
    "missing_gyr = [c for c in needed if c not in gyro_raw.columns]\n",
    "print(\"Missing in accel:\", missing_acc)\n",
    "print(\"Missing in gyro :\", missing_gyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddf68a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>sample_time_offset</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/24/2025, 07:52:19 AM</td>\n",
       "      <td>766</td>\n",
       "      <td>[\"0\",\"10\",\"29\",\"38\",\"48\",\"57\",\"66\",\"77\",\"85\",\"...</td>\n",
       "      <td>[\"-62.48186\",\"-27.60828\",\"-95.41802\",\"-155.478...</td>\n",
       "      <td>[\"-758.6971\",\"-984.1958\",\"-1240.532\",\"-1338.82...</td>\n",
       "      <td>[\"-1097.585\",\"-1221.784\",\"-1086.742\",\"-957.614...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/24/2025, 07:52:20 AM</td>\n",
       "      <td>23</td>\n",
       "      <td>[\"0\",\"9\",\"19\",\"28\",\"38\",\"48\",\"57\",\"67\",\"77\",\"8...</td>\n",
       "      <td>[\"-178.7271\",\"-161.2903\",\"-133.1977\",\"-124.479...</td>\n",
       "      <td>[\"-1360.991\",\"-1342.681\",\"-1269.442\",\"-1171.14...</td>\n",
       "      <td>[\"-777.2302\",\"-619.5170\",\"-460.8181\",\"-345.490...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp  timestamp_ms  \\\n",
       "0  03/24/2025, 07:52:19 AM           766   \n",
       "1  03/24/2025, 07:52:20 AM            23   \n",
       "\n",
       "                                  sample_time_offset  \\\n",
       "0  [\"0\",\"10\",\"29\",\"38\",\"48\",\"57\",\"66\",\"77\",\"85\",\"...   \n",
       "1  [\"0\",\"9\",\"19\",\"28\",\"38\",\"48\",\"57\",\"67\",\"77\",\"8...   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [\"-62.48186\",\"-27.60828\",\"-95.41802\",\"-155.478...   \n",
       "1  [\"-178.7271\",\"-161.2903\",\"-133.1977\",\"-124.479...   \n",
       "\n",
       "                                                   y  \\\n",
       "0  [\"-758.6971\",\"-984.1958\",\"-1240.532\",\"-1338.82...   \n",
       "1  [\"-1360.991\",\"-1342.681\",\"-1269.442\",\"-1171.14...   \n",
       "\n",
       "                                                   z  \n",
       "0  [\"-1097.585\",\"-1221.784\",\"-1086.742\",\"-957.614...  \n",
       "1  [\"-777.2302\",\"-619.5170\",\"-460.8181\",\"-345.490...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>sample_time_offset</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/24/2025, 07:52:19 AM</td>\n",
       "      <td>795</td>\n",
       "      <td>[\"0\",\"9\",\"19\",\"38\",\"48\",\"57\",\"67\",\"76\",\"85\",\"9...</td>\n",
       "      <td>[\"39.15614\",\"32.96125\",\"22.04125\",\"1.041086\",\"...</td>\n",
       "      <td>[\"-7.520049\",\"-10.77502\",\"-9.620019\",\"-4.79006...</td>\n",
       "      <td>[\"7.881836\",\"7.742001\",\"12.78200\",\"2.981754\",\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/24/2025, 07:52:20 AM</td>\n",
       "      <td>52</td>\n",
       "      <td>[\"0\",\"9\",\"19\",\"28\",\"38\",\"48\",\"57\",\"67\",\"76\",\"8...</td>\n",
       "      <td>[\"-24.26378\",\"-35.91878\",\"-44.66883\",\"-50.3738...</td>\n",
       "      <td>[\"-12.10503\",\"-11.82503\",\"-11.30004\",\"-9.90004...</td>\n",
       "      <td>[\"-0.3430405\",\"-1.078040\",\"-1.533123\",\"-2.1631...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp  timestamp_ms  \\\n",
       "0  03/24/2025, 07:52:19 AM           795   \n",
       "1  03/24/2025, 07:52:20 AM            52   \n",
       "\n",
       "                                  sample_time_offset  \\\n",
       "0  [\"0\",\"9\",\"19\",\"38\",\"48\",\"57\",\"67\",\"76\",\"85\",\"9...   \n",
       "1  [\"0\",\"9\",\"19\",\"28\",\"38\",\"48\",\"57\",\"67\",\"76\",\"8...   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [\"39.15614\",\"32.96125\",\"22.04125\",\"1.041086\",\"...   \n",
       "1  [\"-24.26378\",\"-35.91878\",\"-44.66883\",\"-50.3738...   \n",
       "\n",
       "                                                   y  \\\n",
       "0  [\"-7.520049\",\"-10.77502\",\"-9.620019\",\"-4.79006...   \n",
       "1  [\"-12.10503\",\"-11.82503\",\"-11.30004\",\"-9.90004...   \n",
       "\n",
       "                                                   z  \n",
       "0  [\"7.881836\",\"7.742001\",\"12.78200\",\"2.981754\",\"...  \n",
       "1  [\"-0.3430405\",\"-1.078040\",\"-1.533123\",\"-2.1631...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(accel_raw.head(2))\n",
    "display(gyro_raw.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db0b40",
   "metadata": {},
   "source": [
    "# 4) Convert list-like cells into real Python lists\n",
    "\n",
    "> In the raw files, `sample_time_offset` and `x/y/z` may be stored as JSON strings (like `\"[\"0\",\"20\",\"40\"]\"`) or Python-like lists (like `\"[0, 20, 40]\"`).\n",
    "> We parse them into real lists so we can **explode** them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30798553",
   "metadata": {},
   "source": [
    "2) “Parsing list cells” — why do we parse first?\n",
    "What’s in the raw files\n",
    "\n",
    "Garmin often stores multiple samples inside one row:\n",
    "\n",
    "timestamp (a base time like “2025-03-24 08:00:00”)\n",
    "\n",
    "timestamp_ms (extra milliseconds at the row level)\n",
    "\n",
    "sample_time_offset = a list of per-sample ms offsets within that row (e.g., [0, 20, 40, ...])\n",
    "\n",
    "x, y, z = lists of values (same length as offsets)\n",
    "\n",
    "Sometimes those lists are strings like \"[0, 20, 40]\" or [\"0\",\"20\",\"40\"].\n",
    "\n",
    "Why parse\n",
    "\n",
    "Pandas can’t work with math on stringified lists. We convert them into real Python lists so we can explode them (next step) and compute accurate times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f596cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed list lengths (first row accel): [25, 25, 25, 25]\n",
      "Parsed list lengths (first row gyro): [25, 25, 25, 25]\n"
     ]
    }
   ],
   "source": [
    "def parse_list_cell(v):\n",
    "    \"\"\"Return a Python list from JSON/Python-like representations.\"\"\"\n",
    "    if isinstance(v, (list, tuple, np.ndarray)):\n",
    "        return list(v)\n",
    "    if pd.isna(v):\n",
    "        return []\n",
    "    s = str(v).strip()\n",
    "    # Try JSON first\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        # Then Python literal (safe) e.g. \"[0, 20, 40]\"\n",
    "        try:\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            # Fallback: try comma-split\n",
    "            s = s.strip(\"[]\")\n",
    "            if not s:\n",
    "                return []\n",
    "            return [pd.to_numeric(x, errors=\"coerce\") for x in s.split(\",\")]\n",
    "\n",
    "# Apply to both dataframes\n",
    "for df in (accel_raw, gyro_raw):\n",
    "    for c in [\"sample_time_offset\", \"x\", \"y\", \"z\"]:\n",
    "        df[c] = df[c].apply(parse_list_cell)\n",
    "\n",
    "print(\"Parsed list lengths (first row accel):\",\n",
    "      [len(accel_raw.iloc[0][c]) for c in [\"sample_time_offset\",\"x\",\"y\",\"z\"]])\n",
    "print(\"Parsed list lengths (first row gyro):\",\n",
    "      [len(gyro_raw.iloc[0][c]) for c in [\"sample_time_offset\",\"x\",\"y\",\"z\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "621e2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(accel_raw.head(2))\n",
    "# display(gyro_raw.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713fcc3d",
   "metadata": {},
   "source": [
    "# 5) Drop any rows where list lengths are mismatched\n",
    "\n",
    "> Each row’s `offsets`, `x`, `y`, and `z` must have the **same length**.\n",
    "\n",
    "> If not, we drop that row (rare, but safer than guessing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1af23563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accel bad rows: 0  | Gyro bad rows: 0\n"
     ]
    }
   ],
   "source": [
    "def ok_lengths(row):\n",
    "    a = len(row[\"sample_time_offset\"])\n",
    "    b = len(row[\"x\"]); c = len(row[\"y\"]); d = len(row[\"z\"])\n",
    "    return (a == b == c == d)\n",
    "\n",
    "acc_ok = accel_raw.apply(ok_lengths, axis=1)\n",
    "gyr_ok = gyro_raw.apply(ok_lengths, axis=1)\n",
    "\n",
    "print(\"Accel bad rows:\", (~acc_ok).sum(), \" | Gyro bad rows:\", (~gyr_ok).sum())\n",
    "\n",
    "accel_raw = accel_raw.loc[acc_ok].reset_index(drop=True).copy()\n",
    "gyro_raw  = gyro_raw.loc[gyr_ok].reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95621a15",
   "metadata": {},
   "source": [
    "# 6) Explode to **one row per sample** (accel & gyro)\n",
    "\n",
    "> We convert batched rows into **per-sample** rows.\n",
    "\n",
    "> Then we create **true timestamps** as:\n",
    "\n",
    "> `timestamp_true = to_datetime(timestamp, UTC) + timestamp_ms (ms) + sample_time_offset (ms)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881202b5",
   "metadata": {},
   "source": [
    "3) “Explode to one row per sample” — why?\n",
    "What “explode” does\n",
    "\n",
    "After parsing, each row still contains arrays. explode turns that into one row per actual sample:\n",
    "\n",
    "Row 1 with offset 0 → sample 1\n",
    "\n",
    "Row 1 with offset 20 → sample 2\n",
    "\n",
    "…\n",
    "\n",
    "Why it’s important\n",
    "\n",
    "All downstream steps (alignment, resampling, modeling) expect one sample per row with a single timestamp and scalar Ax, Ay, Az (and later Gx, Gy, Gz).\n",
    "\n",
    "If we skip explode, we’d be averaging lists or merging lists → you saw those “TypeError: list” errors earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0ad429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accel_long: (363400, 4) gyro_long: (363400, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-24 07:52:19.766000+00:00</td>\n",
       "      <td>-62.48186</td>\n",
       "      <td>-758.6971</td>\n",
       "      <td>-1097.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-24 07:52:19.776000+00:00</td>\n",
       "      <td>-27.60828</td>\n",
       "      <td>-984.1958</td>\n",
       "      <td>-1221.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-24 07:52:19.795000+00:00</td>\n",
       "      <td>-95.41802</td>\n",
       "      <td>-1240.5320</td>\n",
       "      <td>-1086.742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp        Ax         Ay        Az\n",
       "0 2025-03-24 07:52:19.766000+00:00 -62.48186  -758.6971 -1097.585\n",
       "1 2025-03-24 07:52:19.776000+00:00 -27.60828  -984.1958 -1221.784\n",
       "2 2025-03-24 07:52:19.795000+00:00 -95.41802 -1240.5320 -1086.742"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "      <th>Gz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-24 07:52:19.795000+00:00</td>\n",
       "      <td>39.15614</td>\n",
       "      <td>-7.520049</td>\n",
       "      <td>7.881836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-24 07:52:19.804000+00:00</td>\n",
       "      <td>32.96125</td>\n",
       "      <td>-10.775020</td>\n",
       "      <td>7.742001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-24 07:52:19.814000+00:00</td>\n",
       "      <td>22.04125</td>\n",
       "      <td>-9.620019</td>\n",
       "      <td>12.782000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp        Gx         Gy         Gz\n",
       "0 2025-03-24 07:52:19.795000+00:00  39.15614  -7.520049   7.881836\n",
       "1 2025-03-24 07:52:19.804000+00:00  32.96125 -10.775020   7.742001\n",
       "2 2025-03-24 07:52:19.814000+00:00  22.04125  -9.620019  12.782000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explode in-place (pandas can explode multiple columns at once)\n",
    "# The explode() method converts each element of the specified column(s) into a row.\n",
    "accel_long = accel_raw.explode([\"sample_time_offset\",\"x\",\"y\",\"z\"], ignore_index=True).copy()\n",
    "gyro_long  = gyro_raw.explode ([\"sample_time_offset\",\"x\",\"y\",\"z\"], ignore_index=True).copy()\n",
    "\n",
    "# Build true timestamps (UTC)\n",
    "def make_true_time(df):\n",
    "    ''' Why: The base timestamp is only row‑level. \n",
    "    The offset gives the exact time inside the row. \n",
    "    Using true time preserves rhythm/frequency and makes alignment correct. '''\n",
    "    # base = timestamp (UTC) + timestamp_ms\n",
    "    base = pd.to_datetime(df[\"timestamp\"], utc=True, errors=\"coerce\") \\\n",
    "           + pd.to_timedelta(pd.to_numeric(df[\"timestamp_ms\"], errors=\"coerce\").fillna(0).astype(\"int64\"), unit=\"ms\")\n",
    "    # add per-sample offset\n",
    "    off  = pd.to_timedelta(pd.to_numeric(df[\"sample_time_offset\"], errors=\"coerce\").fillna(0).astype(\"int64\"), unit=\"ms\")\n",
    "    return base + off\n",
    "\n",
    "accel_long[\"timestamp\"] = make_true_time(accel_long)\n",
    "gyro_long[\"timestamp\"]  = make_true_time(gyro_long)\n",
    "\n",
    "# Keep only what we need, and rename axes with prefixes\n",
    "accel_long = accel_long[[\"timestamp\",\"x\",\"y\",\"z\"]].rename(columns={\"x\":\"Ax\",\"y\":\"Ay\",\"z\":\"Az\"})\n",
    "gyro_long  = gyro_long [[\"timestamp\",\"x\",\"y\",\"z\"]].rename(columns={\"x\":\"Gx\",\"y\":\"Gy\",\"z\":\"Gz\"})\n",
    "\n",
    "# Ensure numeric types\n",
    "for c in [\"Ax\",\"Ay\",\"Az\"]:\n",
    "    accel_long[c] = pd.to_numeric(accel_long[c], errors=\"coerce\")\n",
    "for c in [\"Gx\",\"Gy\",\"Gz\"]:\n",
    "    gyro_long[c]  = pd.to_numeric(gyro_long[c],  errors=\"coerce\")\n",
    "\n",
    "# Sort\n",
    "accel_long = accel_long.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "gyro_long  = gyro_long.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "print(\"accel_long:\", accel_long.shape, \"gyro_long:\", gyro_long.shape)\n",
    "display(accel_long.head(3))\n",
    "display(gyro_long.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc9632",
   "metadata": {},
   "source": [
    "#### “True timestamp” — why we build it (and how)\n",
    "The formula\n",
    "\n",
    "For each exploded sample we compute:\n",
    "\n",
    "true_time = to_utc_datetime(timestamp) + timestamp_ms (row-level) + sample_time_offset (per-sample)\n",
    "\n",
    "Why do this\n",
    "\n",
    "The base timestamp is coarse (row-level).\n",
    "\n",
    "The actual sample times are timestamp + timestamp_ms + offset.\n",
    "Using true times:\n",
    "\n",
    "aligns accel↔gyro at the exact instant;\n",
    "\n",
    "preserves fine timing (vital for frequency content and motion phases);\n",
    "\n",
    "avoids “smearing” or jitter caused by treating all batched samples as the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4947e47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unit check] accel looks like: mG | median norm ~ 1002.321\n",
      "Converted accel: mG → m/s²\n",
      "[After] accel looks like: m/s^2 | median norm ~ 9.829\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def guess_accel_unit(df, cols=(\"Ax\",\"Ay\",\"Az\")):\n",
    "    norm = np.sqrt((df[list(cols)]**2).sum(axis=1))\n",
    "    m = float(np.nanmedian(norm))\n",
    "    if 700 <= m <= 1300: return \"mG\", m      # ~1000 when still\n",
    "    if 0.7 <= m <= 1.3:  return \"g\", m       # ~1 when still\n",
    "    if 7.0 <= m <= 12.5: return \"m/s^2\", m   # ~9.81 when still\n",
    "    return \"unknown\", m\n",
    "\n",
    "unit, med = guess_accel_unit(accel_long, (\"Ax\",\"Ay\",\"Az\"))\n",
    "print(f\"[Unit check] accel looks like: {unit} | median norm ~ {med:.3f}\")\n",
    "\n",
    "# Convert only if needed\n",
    "if unit == \"mG\":\n",
    "    factor = 9.80665 / 1000.0   # mG -> m/s^2\n",
    "    for c in [\"Ax\",\"Ay\",\"Az\"]:\n",
    "        accel_long[c] = accel_long[c].astype(float) * factor\n",
    "    print(\"Converted accel: mG → m/s²\")\n",
    "elif unit == \"g\":\n",
    "    factor = 9.80665            # g -> m/s^2\n",
    "    for c in [\"Ax\",\"Ay\",\"Az\"]:\n",
    "        accel_long[c] = accel_long[c].astype(float) * factor\n",
    "    print(\"Converted accel: g → m/s²\")\n",
    "else:\n",
    "    print(\"No conversion applied (already m/s² or unknown).\")\n",
    "\n",
    "# sanity after conversion\n",
    "unit2, med2 = guess_accel_unit(accel_long, (\"Ax\",\"Ay\",\"Az\"))\n",
    "print(f\"[After] accel looks like: {unit2} | median norm ~ {med2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1ce93",
   "metadata": {},
   "source": [
    "# 7) Align accel & gyro by **nearest timestamp** (with tolerance)\n",
    "\n",
    "> For each accel sample, find the nearest gyro sample within a small time window.\n",
    "> If there’s no gyro within the window, we drop that accel row.\n",
    "> We also print **match ratio** and basic **lag** statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "345de026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched within 1 ms: 95.1%\n",
      "Lag ms — mean: -0.466, std: 0.499, max_abs: 1.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "      <th>Gz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-24 07:52:19.795000+00:00</td>\n",
       "      <td>-0.935731</td>\n",
       "      <td>-12.165463</td>\n",
       "      <td>-10.657298</td>\n",
       "      <td>39.156140</td>\n",
       "      <td>-7.520049</td>\n",
       "      <td>7.881836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-24 07:52:19.804000+00:00</td>\n",
       "      <td>-1.524719</td>\n",
       "      <td>-13.129398</td>\n",
       "      <td>-9.390991</td>\n",
       "      <td>32.961250</td>\n",
       "      <td>-10.775020</td>\n",
       "      <td>7.742001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-24 07:52:19.814000+00:00</td>\n",
       "      <td>-1.610218</td>\n",
       "      <td>-13.639726</td>\n",
       "      <td>-7.941018</td>\n",
       "      <td>22.041250</td>\n",
       "      <td>-9.620019</td>\n",
       "      <td>12.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-24 07:52:19.832000+00:00</td>\n",
       "      <td>-1.581718</td>\n",
       "      <td>-12.864795</td>\n",
       "      <td>-5.195736</td>\n",
       "      <td>1.041086</td>\n",
       "      <td>-4.790063</td>\n",
       "      <td>2.981754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-24 07:52:19.843000+00:00</td>\n",
       "      <td>-1.220725</td>\n",
       "      <td>-11.929201</td>\n",
       "      <td>-3.484769</td>\n",
       "      <td>-14.568870</td>\n",
       "      <td>-7.275052</td>\n",
       "      <td>1.441816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp        Ax         Ay         Az         Gx  \\\n",
       "0 2025-03-24 07:52:19.795000+00:00 -0.935731 -12.165463 -10.657298  39.156140   \n",
       "1 2025-03-24 07:52:19.804000+00:00 -1.524719 -13.129398  -9.390991  32.961250   \n",
       "2 2025-03-24 07:52:19.814000+00:00 -1.610218 -13.639726  -7.941018  22.041250   \n",
       "3 2025-03-24 07:52:19.832000+00:00 -1.581718 -12.864795  -5.195736   1.041086   \n",
       "4 2025-03-24 07:52:19.843000+00:00 -1.220725 -11.929201  -3.484769 -14.568870   \n",
       "\n",
       "          Gy         Gz  \n",
       "0  -7.520049   7.881836  \n",
       "1 -10.775020   7.742001  \n",
       "2  -9.620019  12.782000  \n",
       "3  -4.790063   2.981754  \n",
       "4  -7.275052   1.441816  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tolerance = pd.Timedelta(milliseconds=MERGE_TOLERANCE_MS)\n",
    "\n",
    "gyro_for_merge = gyro_long.rename(columns={\"timestamp\":\"gyro_ts\"})\n",
    "merged = pd.merge_asof(\n",
    "    accel_long.sort_values(\"timestamp\"),\n",
    "    gyro_for_merge.sort_values(\"gyro_ts\"),\n",
    "    left_on=\"timestamp\", right_on=\"gyro_ts\",\n",
    "    direction=\"nearest\", tolerance=tolerance\n",
    ")\n",
    "\n",
    "have_gyro = merged[[\"Gx\",\"Gy\",\"Gz\"]].notna().all(axis=1)\n",
    "match_ratio = have_gyro.mean()\n",
    "lag_ms = ((merged.loc[have_gyro, \"timestamp\"].astype(\"int64\")\n",
    "          - merged.loc[have_gyro, \"gyro_ts\"].astype(\"int64\")) / 1e6)\n",
    "\n",
    "print(f\"Matched within {MERGE_TOLERANCE_MS} ms: {match_ratio:.1%}\")\n",
    "if len(lag_ms):\n",
    "    print(f\"Lag ms — mean: {lag_ms.mean():.3f}, std: {lag_ms.std():.3f}, max_abs: {np.abs(lag_ms).max():.3f}\")\n",
    "else:\n",
    "    print(\"No matched samples. Increase MERGE_TOLERANCE_MS?\")\n",
    "\n",
    "# Keep only matched rows and drop helper column\n",
    "merged = merged.loc[have_gyro, [\"timestamp\",\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\"]].reset_index(drop=True)\n",
    "display(merged.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ee67582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345418, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81fe5c1",
   "metadata": {},
   "source": [
    "# 8) Resample to **exact 50 Hz** (gap-free)\n",
    "\n",
    "\n",
    "> We convert the aligned series into a perfect **50 Hz** timeline (every 20 ms).\n",
    "> We aggregate with `mean` within bins and use time interpolation for tiny gaps.\n",
    "> Finally we add `timestamp_ms` for convenience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31713620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed @ 50 Hz: (181699, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "      <th>Gz</th>\n",
       "      <th>timestamp_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-24 07:52:19.780000+00:00</td>\n",
       "      <td>-0.935731</td>\n",
       "      <td>-12.165463</td>\n",
       "      <td>-10.657298</td>\n",
       "      <td>39.156140</td>\n",
       "      <td>-7.520049</td>\n",
       "      <td>7.881836</td>\n",
       "      <td>1742802739780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-24 07:52:19.800000+00:00</td>\n",
       "      <td>-1.567468</td>\n",
       "      <td>-13.384562</td>\n",
       "      <td>-8.666005</td>\n",
       "      <td>27.501250</td>\n",
       "      <td>-10.197519</td>\n",
       "      <td>10.262000</td>\n",
       "      <td>1742802739800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-24 07:52:19.820000+00:00</td>\n",
       "      <td>-1.581718</td>\n",
       "      <td>-12.864795</td>\n",
       "      <td>-5.195736</td>\n",
       "      <td>1.041086</td>\n",
       "      <td>-4.790063</td>\n",
       "      <td>2.981754</td>\n",
       "      <td>1742802739820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-24 07:52:19.840000+00:00</td>\n",
       "      <td>-1.206475</td>\n",
       "      <td>-11.348005</td>\n",
       "      <td>-2.967611</td>\n",
       "      <td>-21.761370</td>\n",
       "      <td>-7.012552</td>\n",
       "      <td>0.549316</td>\n",
       "      <td>1742802739840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-24 07:52:19.860000+00:00</td>\n",
       "      <td>-1.467720</td>\n",
       "      <td>-7.912796</td>\n",
       "      <td>-1.338808</td>\n",
       "      <td>-44.003680</td>\n",
       "      <td>-6.960001</td>\n",
       "      <td>-3.230397</td>\n",
       "      <td>1742802739860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp        Ax         Ay         Az         Gx  \\\n",
       "0 2025-03-24 07:52:19.780000+00:00 -0.935731 -12.165463 -10.657298  39.156140   \n",
       "1 2025-03-24 07:52:19.800000+00:00 -1.567468 -13.384562  -8.666005  27.501250   \n",
       "2 2025-03-24 07:52:19.820000+00:00 -1.581718 -12.864795  -5.195736   1.041086   \n",
       "3 2025-03-24 07:52:19.840000+00:00 -1.206475 -11.348005  -2.967611 -21.761370   \n",
       "4 2025-03-24 07:52:19.860000+00:00 -1.467720  -7.912796  -1.338808 -44.003680   \n",
       "\n",
       "          Gy         Gz   timestamp_ms  \n",
       "0  -7.520049   7.881836  1742802739780  \n",
       "1 -10.197519  10.262000  1742802739800  \n",
       "2  -4.790063   2.981754  1742802739820  \n",
       "3  -7.012552   0.549316  1742802739840  \n",
       "4  -6.960001  -3.230397  1742802739860  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step_ms = int(round(1000 / TARGET_HZ))\n",
    "freq = f\"{step_ms}ms\"\n",
    "\n",
    "# Ensure numeric (protect against stray objects)\n",
    "for c in [\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\"]:\n",
    "    merged[c] = pd.to_numeric(merged[c], errors=\"coerce\")\n",
    "\n",
    "fixed = (merged\n",
    "         .set_index(\"timestamp\")[[\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\"]]\n",
    "         .resample(freq)\n",
    "         .mean()\n",
    "         .interpolate(method=\"time\", limit_direction=\"both\")\n",
    "         .reset_index())\n",
    "\n",
    "# Add timestamp_ms (int)\n",
    "fixed[\"timestamp_ms\"] = (fixed[\"timestamp\"].astype(\"int64\") // 10**6).astype(\"int64\")\n",
    "\n",
    "print(\"Fixed @\", TARGET_HZ, \"Hz:\", fixed.shape)\n",
    "display(fixed.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d6aef",
   "metadata": {},
   "source": [
    "“Exact 50 Hz from the merged data” — how & why the row counts change\n",
    "Why resample\n",
    "\n",
    "After alignment, your timestamps are irregular (tiny jitters).\n",
    "\n",
    "Models and feature windows are simpler if the timeline is a perfect grid: every 20 ms at 50 Hz.\n",
    "\n",
    "How we do it (one line conceptually)\n",
    "fixed = (merged.set_index('timestamp')\n",
    "               .resample('20ms')\n",
    "               .mean()\n",
    "               .interpolate('time')\n",
    "               .reset_index())\n",
    "\n",
    "\n",
    "resample('20ms') bins samples into exact 20 ms slots\n",
    "\n",
    "mean() combines any duplicates that land in the same bin\n",
    "\n",
    "interpolate('time') fills tiny holes smoothly (useful if a bin is empty)\n",
    "\n",
    "Why your row counts look like that\n",
    "\n",
    "From your debug earlier:\n",
    "\n",
    "Start ms: 1 742 802 739 780\n",
    "\n",
    "End ms: 1 742 806 373 740\n",
    "\n",
    "Span = 3 633 960 ms = 3 633.96 s\n",
    "\n",
    "At 50 Hz, expected rows ≈ 3 633.96 × 50 ≈ 181 698.\n",
    "Adding one because we include both ends → ≈ 181 699 rows.\n",
    "\n",
    "That matches what you observed after resampling: about 181,699 rows and 8 columns (timestamp, timestamp_ms, Ax..Gz).\n",
    "\n",
    "Your earlier merged frame had ~345,851 rows because before resampling it’s irregular (often >50Hz effective rate due to how batched offsets land). Resampling regularizes it to the exact 50 Hz grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcc020c",
   "metadata": {},
   "source": [
    "\n",
    "# 9) Sanity checks (order, duplicates, finites, rough ranges)\n",
    "\n",
    "**Markdown**\n",
    "\n",
    "> Quick guards to catch obvious problems early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc5893f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate timestamps: 0\n",
      "Accel magnitude OK: True | Gyro magnitude OK: True\n",
      "Duration: 3633.96s | Rows: 181699 | Target Hz: 50\n"
     ]
    }
   ],
   "source": [
    "# monotonic timestamps\n",
    "assert fixed[\"timestamp\"].is_monotonic_increasing, \"Timestamps not sorted!\"\n",
    "\n",
    "# duplicates\n",
    "dupes = fixed[\"timestamp\"].duplicated().sum()\n",
    "print(\"Duplicate timestamps:\", dupes)\n",
    "\n",
    "# finite values\n",
    "assert np.isfinite(fixed[[\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\"]]).all().all(), \"Non-finite values found!\"\n",
    "\n",
    "# rough magnitude checks (tweak if your units differ)\n",
    "accel_ok = (fixed[[\"Ax\",\"Ay\",\"Az\"]].abs() < 50).all().all()      # ~5g if m/s² (~49)\n",
    "gyro_ok  = (fixed[[\"Gx\",\"Gy\",\"Gz\"]].abs() < 2000).all().all()    # <2000 deg/s typical\n",
    "print(\"Accel magnitude OK:\", accel_ok, \"| Gyro magnitude OK:\", gyro_ok)\n",
    "\n",
    "duration_s = (fixed[\"timestamp\"].iloc[-1] - fixed[\"timestamp\"].iloc[0]).total_seconds()\n",
    "print(f\"Duration: {duration_s:.2f}s | Rows: {len(fixed)} | Target Hz: {TARGET_HZ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cf6846",
   "metadata": {},
   "source": [
    "# 10) Save outputs (Parquet + CSV)\n",
    "\n",
    "**Markdown**\n",
    "\n",
    "> Parquet is fast & typed; CSV is handy to eyeball in Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e96c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# PARQUET_PATH = \"processed/session_50hz.parquet\"\n",
    "# CSV_PATH     = \"processed/session_50hz.csv\"\n",
    "\n",
    "# import os\n",
    "# os.makedirs(os.path.dirname(PARQUET_PATH), exist_ok=True)\n",
    "\n",
    "# fixed.to_parquet(PARQUET_PATH, index=False)\n",
    "# fixed.to_csv(CSV_PATH, index=False)\n",
    "\n",
    "# print(\"Saved:\", PARQUET_PATH, \"|\", CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61a617",
   "metadata": {},
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1696d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Session overview\n",
    "# import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "# print(\"Rows:\", len(fixed))\n",
    "# print(\"Time range:\", fixed[\"timestamp\"].min(), \"→\", fixed[\"timestamp\"].max())\n",
    "\n",
    "# # sampling jitter\n",
    "# dt = fixed[\"timestamp\"].diff().dt.total_seconds().dropna()\n",
    "# print(\"Δt stats (s): min\", dt.min(), \"max\", dt.max(), \"mean\", dt.mean())\n",
    "\n",
    "# fixed.describe()[[\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg = fixed.set_index(\"timestamp\").iloc[0:50*60]\n",
    "# ax = seg[[\"Ax\",\"Ay\",\"Az\"]].plot(figsize=(12,4), title=\"Accel (m/s²) — first 60 s\"); ax.legend(loc=\"upper right\")\n",
    "# ax = seg[[\"Gx\",\"Gy\",\"Gz\"]].plot(figsize=(12,4), title=\"Gyro (deg/s) — first 60 s\"); ax.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed[[\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\"]].hist(bins=60, figsize=(12,8))\n",
    "\n",
    "# fixed[\"A_norm\"] = np.sqrt((fixed[[\"Ax\",\"Ay\",\"Az\"]]**2).sum(axis=1))\n",
    "# fixed[\"G_norm\"] = np.sqrt((fixed[[\"Gx\",\"Gy\",\"Gz\"]]**2).sum(axis=1))\n",
    "# fixed[[\"A_norm\",\"G_norm\"]].plot(figsize=(12,4), title=\"Vector norms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579604e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import welch\n",
    "# fs = 50\n",
    "# f, P = welch(fixed[\"A_norm\"].values, fs=fs, nperseg=1024, noverlap=512)\n",
    "# plt.figure(figsize=(8,4)); plt.semilogy(f, P); plt.xlim(0,10); plt.xlabel(\"Hz\"); plt.ylabel(\"Power\"); plt.title(\"PSD of A_norm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b997a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.pyplot import specgram\n",
    "# plt.figure(figsize=(10,4))\n",
    "# plt.specgram(fixed[\"A_norm\"].values, NFFT=256, Fs=fs, noverlap=128)\n",
    "# plt.ylim(0,10); plt.title(\"Spectrogram of A_norm\"); plt.xlabel(\"time (s)\"); plt.ylabel(\"Hz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a70a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = fixed[[\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\"]].corr().round(2)\n",
    "# print(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7375ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll = fixed[[\"Ax\",\"Ay\",\"Az\"]].rolling(50*5).agg([\"mean\",\"std\"])  # 5 s window\n",
    "# roll.columns = [\"_\".join(c) for c in roll.columns]\n",
    "# roll[[\"Ax_mean\",\"Ax_std\"]].plot(figsize=(12,4), title=\"Accel X — rolling mean/std (5 s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa13cd9c",
   "metadata": {},
   "source": [
    "### Why these steps matter (in one-liners)\n",
    "\n",
    "#### Gravity split: separates posture (slow) from motion (fast) → cleaner features & PSD.\n",
    "\n",
    "#### Winsorize: protects features from rare spikes → more stable EDA & training.\n",
    "\n",
    "#### QC facts: tiny dashboard numbers → easy to spot bad recordings and enforce data quality.\n",
    "\n",
    "#### Tidy artifact: one canonical dataset → consistent across notebooks and .py pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b17fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Gravity split (WHAT / WHY / HOW)\n",
    "\n",
    "# What: split each accel axis into gravity (very slow, posture/orientation) and dynamic (motion you care about).\n",
    "\n",
    "# Why: models/EDA are more stable on dynamic signals; gravity can mask steps/cadence and inflate low-freq energy.\n",
    "\n",
    "# How: low-pass filter (≈0.3 Hz) gives gravity; dynamic = raw − gravity.\n",
    "\n",
    "# '''\n",
    "\n",
    "# from scipy.signal import butter, filtfilt\n",
    "# import numpy as np\n",
    "\n",
    "# fs = 50.0          # Hz\n",
    "# cut = 0.3          # Hz (very slow = gravity/orientation)\n",
    "# b, a = butter(2, cut/(fs/2), btype=\"low\")\n",
    "\n",
    "# for c in [\"Ax\",\"Ay\",\"Az\"]:\n",
    "#     grav = filtfilt(b, a, fixed[c].astype(float).values)\n",
    "#     fixed[c+\"_grav\"] = grav\n",
    "#     fixed[c+\"_dyn\"]  = fixed[c] - grav\n",
    "\n",
    "# # quick sanity\n",
    "# fixed[\"A_dyn_norm\"]  = np.sqrt((fixed[[f\"{c}_dyn\"  for c in [\"Ax\",\"Ay\",\"Az\"]]]**2).sum(axis=1))\n",
    "# fixed[\"A_grav_norm\"] = np.sqrt((fixed[[f\"{c}_grav\" for c in [\"Ax\",\"Ay\",\"Az\"]]]**2).sum(axis=1))\n",
    "# print(\"gravity norm median ~\", float(fixed[\"A_grav_norm\"].median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# De-spike / Winsorize (optional but useful)\n",
    "\n",
    "# What: clip extreme outliers (sensor glitches).\n",
    "\n",
    "# Why: spikes wreck RMS/energy/PSD and can destabilize training.\n",
    "\n",
    "# How: clip each channel at very wide percentiles (0.1% / 99.9%) so you keep almost everything.\n",
    "# '''\n",
    "\n",
    "# for c in [\"Ax\",\"Ay\",\"Az\",\"Gx\",\"Gy\",\"Gz\",\"Ax_dyn\",\"Ay_dyn\",\"Az_dyn\"]:\n",
    "#     if c in fixed.columns:\n",
    "#         lo, hi = fixed[c].quantile([0.001, 0.999])\n",
    "#         fixed[c] = fixed[c].clip(lo, hi)\n",
    "# print(\"Winsorize: done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Quality facts (QC metrics you can log)\n",
    "\n",
    "# What: tiny set of numbers proving the file is healthy.\n",
    "\n",
    "# Why: perfect for your thesis pipeline & automation; quick red/green checks.\n",
    "\n",
    "# How: compute once, print/save.\n",
    "\n",
    "# '''\n",
    "\n",
    "# qc = {}\n",
    "# # cadence grid\n",
    "# dt = fixed[\"timestamp\"].diff().dt.total_seconds().dropna()\n",
    "# qc[\"hz_mean\"] = float(1.0 / dt.mean()) if len(dt) else float(\"nan\")\n",
    "# qc[\"dupe_ts\"] = int(fixed[\"timestamp\"].duplicated().sum())\n",
    "\n",
    "# # accel gravity check (~9.8 when still)\n",
    "# fixed[\"A_norm\"] = np.sqrt((fixed[[\"Ax\",\"Ay\",\"Az\"]]**2).sum(axis=1))\n",
    "# qc[\"A_norm_median\"] = float(fixed[\"A_norm\"].median())\n",
    "\n",
    "# # gyro sanity (95th percentile)\n",
    "# fixed[\"G_norm\"] = np.sqrt((fixed[[\"Gx\",\"Gy\",\"Gz\"]]**2).sum(axis=1))\n",
    "# qc[\"G_norm_p95\"] = float(fixed[\"G_norm\"].quantile(0.95))\n",
    "\n",
    "# # dynamic energy, if you computed it\n",
    "# if all(col in fixed.columns for col in [\"Ax_dyn\",\"Ay_dyn\",\"Az_dyn\"]):\n",
    "#     fixed[\"A_dyn_norm\"] = np.sqrt((fixed[[\"Ax_dyn\",\"Ay_dyn\",\"Az_dyn\"]]**2).sum(axis=1))\n",
    "#     qc[\"A_dyn_norm_median\"] = float(fixed[\"A_dyn_norm\"].median())\n",
    "\n",
    "# print(\"QC summary:\", qc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Save a tidy artifact (so later steps can load it)\n",
    "\n",
    "# What: persist a clean table you and your future .py pipeline can reuse.\n",
    "\n",
    "# Why: reproducibility & easy hand-off to modeling.\n",
    "\n",
    "# How: save Parquet (fast/typed) and CSV (human-readable).\n",
    "# '''\n",
    "\n",
    "# import os, datetime as dt\n",
    "# os.makedirs(\"processed\", exist_ok=True)\n",
    "# stamp = dt.datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# cols = [c for c in fixed.columns]  # keep all; or filter if you like\n",
    "# parquet_path = f\"processed/session_50hz_tidy_{stamp}.parquet\"\n",
    "# csv_path     = f\"processed/session_50hz_tidy_{stamp}.csv\"\n",
    "\n",
    "# fixed[cols].to_parquet(parquet_path, index=False)\n",
    "# fixed[cols].to_csv(csv_path, index=False)\n",
    "\n",
    "# print(\"Saved:\", parquet_path, \"|\", csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3636059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
