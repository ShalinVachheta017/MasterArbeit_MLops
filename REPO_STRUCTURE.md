**Repository Structure**

This document describes the top-level folders and important subfolders/files in this repository. Paths are relative to the repository root.

**Top-Level**
- **`01_data/`**: Raw, processed and prepared datasets.
- **`02_src/`**: Source code (preprocessing, analysis, training helpers).
- **`03_models/`**: Saved model artifacts (pretrained and trained models).
- **`04_notebooks/`**: Jupyter notebooks for experiments and exploration.
- **`05_outputs/`**: Generated analysis outputs and reports.
- **`06_logs/`**: Logs from preprocessing, training and evaluation runs.
- **`07_docs/`**: Project documentation, planning, and mentor communications.
- **`08_config/`**: Environment and dependency configs (e.g. `requirements.txt`).
- **`09_archive/`**: Backups and older copies of data, notebooks and source.
- **`README.md`**: High-level project overview and quick-start notes.

**`01_data/`**
- **`raw/`**: Original labeled dataset and raw exports.+
- **`processed/`**: Production/unlabeled processed CSVs (e.g. `sensor_fused_50Hz.csv`).
- **`prepared/`**: Windowed numpy arrays and scaler/config JSONs used for training/validation/test.
  - Notable: `sensor_fused_50Hz.csv`, `prepared/*_X.npy`, and `config.json` (scaler params).

**`02_src/`**
- **`path_config.py`**: Centralized path constants (project-local imports).
- **`analysis/`**: Analysis scripts (e.g. `analyze_data.py`, `inspect_model.py`).
- **`preprocessing/`**: Data preprocessing and pipeline code (sliding windows, resampling, scaler usage).
  - Notable: `sensor_data_pipeline.py`, `example_usage.py`, `prepare_training_data.py`, `prepare_production_data.py`.
- **`training/`**: Training-related utilities and orchestration scripts.

**`03_models/`**
- **`pretrained/`**: Pretrained model used for inference. Example: `fine_tuned_model_1dcnnbilstm.keras` and `model_info.json`.
- **`trained/`**: Trained models produced during this project (kept separate from mentor-provided pretrained models).

**`04_notebooks/`**
- **`experiments/`**: Notebooks used for scalable experiments (e.g. `scalable.ipynb`).
- **`exploration/`**: Data exploration notebooks (many earlier analyses and processing guides).

**`05_outputs/`**
- **`analysis/`**: Results from data and model analyses (e.g. `f_data_analysis.json`).
- **`reports/`**: Evaluation or report artifacts (PDFs, MDs, CSVs).

**`06_logs/`**
- **`evaluation/`**: Evaluation run logs and summaries.
- **`preprocessing/`**: Logs produced by preprocessing pipelines.
- **`training/`**: Training run logs (if available).

**`07_docs/`**
- **`RESTRUCTURING_COMPLETE.md`**: Notes about repository restructuring.
- **`mentor_communication/`**: Email templates and detailed requests to mentor (e.g. `EMAIL_TO_MENTOR.md`).
- **`planning/`**: Roadmaps and project assessment docs (e.g. `COMPLETE_PIPELINE_ROADMAP.md`).
- **`project_info/`** and **`technical/`**: Detailed project and technical docs.
- Notable retained docs: `PROJECT_STATUS.md` and `DATASET_DIFFERENCE_SUMMARY.md` (canonical summaries created during analysis).

**`08_config/`**
- `requirements.txt`: Python dependency list used for environment setup.

**`09_archive/`**
- Backups of older data, notebooks, and scripts. Useful for historical reference.

**Common workflows & entry points**
- Run preprocessing (example): `python 02_src/preprocessing/sensor_data_pipeline.py` or `python 02_src/preprocessing/prepare_training_data.py`.
- Prepare production data for inference: `python 02_src/preprocessing/prepare_production_data.py` (uses saved scaler config in `01_data/prepared`).
- Inspect model or run quick analysis: `python 02_src/analysis/inspect_model.py` or `python 02_src/analysis/analyze_data.py`.

**Notes & recommendations**
- The repository was recently cleaned to keep only canonical artifacts. Many ad-hoc analysis scripts and temporary outputs were removed â€” check `09_archive/` if something seems missing.
- If you need a smaller or alternate view (e.g. only code files), tell me which folders to expand and I will update this document.

---

Last updated: autogenerated by GitHub Copilot (GPT-5 mini) on local workspace.
